{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrfkYsJS7kjs",
        "outputId": "661f66e9-adbc-4bdb-9862-c0845a710264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.116.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (3.12.14)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
            "Collecting openvino\n",
            "  Downloading openvino-2025.2.0-19140-cp311-cp311-manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Collecting llm-guard\n",
            "  Downloading llm_guard-0.3.16-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.7.21-py3-none-any.whl.metadata (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.34.1)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting optimum[openvino]\n",
            "  Downloading optimum-1.26.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.47.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.20.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
            "Collecting openvino-telemetry>=2023.2.1 (from openvino)\n",
            "  Downloading openvino_telemetry-2025.2.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting optimum-intel>=1.23.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading optimum_intel-1.24.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Collecting bc-detect-secrets==1.5.43 (from llm-guard)\n",
            "  Downloading bc_detect_secrets-1.5.43-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting faker<38,>=37 (from llm-guard)\n",
            "  Downloading faker-37.4.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting fuzzysearch<0.9,>=0.7 (from llm-guard)\n",
            "  Downloading fuzzysearch-0.8.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting json-repair==0.44.1 (from llm-guard)\n",
            "  Downloading json_repair-0.44.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting presidio-analyzer==2.2.358 (from llm-guard)\n",
            "  Downloading presidio_analyzer-2.2.358-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting presidio-anonymizer==2.2.358 (from llm-guard)\n",
            "  Downloading presidio_anonymizer-2.2.358-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tiktoken<1.0,>=0.9 in /usr/local/lib/python3.11/dist-packages (from llm-guard) (0.9.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting structlog>=24 (from llm-guard)\n",
            "  Downloading structlog-25.4.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting unidiff (from bc-detect-secrets==1.5.43->llm-guard)\n",
            "  Downloading unidiff-0.7.5-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio-analyzer==2.2.358->llm-guard)\n",
            "  Downloading phonenumbers-8.13.55-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting tldextract (from presidio-analyzer==2.2.358->llm-guard)\n",
            "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: cryptography<44.1 in /usr/local/lib/python3.11/dist-packages (from presidio-anonymizer==2.2.358->llm-guard) (43.0.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker<38,>=37->llm-guard) (2025.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: datasets>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (4.0.0)\n",
            "Collecting onnx (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting nncf>=2.16.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading nncf-2.17.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting openvino-tokenizers>=2025.1.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading openvino_tokenizers-2025.2.0.1-py3-none-manylinux2014_x86_64.whl.metadata (28 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44.1->presidio-anonymizer==2.2.358->llm-guard) (1.17.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.70.16)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: natsort>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (8.4.0)\n",
            "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ninja<1.12,>=1.10.0.post2 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (5.9.5)\n",
            "Requirement already satisfied: pydot<=3.0.4,>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.0.4)\n",
            "Collecting pymoo>=0.6.0.1 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading pymoo-0.6.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.9.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer==2.2.358->llm-guard)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44.1->presidio-anonymizer==2.2.358->llm-guard) (2.22)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2025.2)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.8.0)\n",
            "Collecting cma>=3.2.2 (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading cma-4.3.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting alive-progress (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading alive_progress-3.3.0-py3-none-any.whl.metadata (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.4.8)\n",
            "Collecting about-time==4.2.1 (from alive-progress->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting graphemeu==0.7.2 (from alive-progress->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading graphemeu-0.7.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino-2025.2.0-19140-cp311-cp311-manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llm_guard-0.3.16-py3-none-any.whl (136 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.7/136.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bc_detect_secrets-1.5.43-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.44.1-py3-none-any.whl (22 kB)\n",
            "Downloading presidio_analyzer-2.2.358-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading presidio_anonymizer-2.2.358-py3-none-any.whl (31 kB)\n",
            "Downloading yt_dlp-2025.7.21-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-37.4.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzysearch-0.8.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino_telemetry-2025.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading optimum_intel-1.24.0-py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.7/348.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.26.1-py3-none-any.whl (424 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.6/424.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-25.4.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nncf-2.17.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino_tokenizers-2025.2.0.1-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonenumbers-8.13.55-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unidiff-0.7.5-py2.py3-none-any.whl (14 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymoo-0.6.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading cma-4.3.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.9/295.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alive_progress-3.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading about_time-4.2.1-py3-none-any.whl (13 kB)\n",
            "Downloading graphemeu-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=d76f395fcdc2b63dbae9f3d5a254eb18cd00df7b23021f6b62658da90c39f3b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: unidiff, pypika, phonenumbers, openvino-telemetry, durationpy, yt-dlp, uvloop, structlog, python-dotenv, pybase64, overrides, openvino, opentelemetry-proto, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, networkx, mmh3, json-repair, humanfriendly, httptools, graphemeu, fuzzysearch, ffmpeg-python, faker, faiss-cpu, Deprecated, cma, bcrypt, backoff, about-time, watchfiles, requests-file, posthog, openvino-tokenizers, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, bc-detect-secrets, alive-progress, tldextract, pymoo, presidio-anonymizer, opentelemetry-semantic-conventions, onnxruntime, nvidia-cusolver-cu12, kubernetes, transformers, opentelemetry-sdk, nncf, optimum, opentelemetry-exporter-otlp-proto-grpc, presidio-analyzer, optimum-intel, chromadb, llm-guard\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.54.0\n",
            "    Uninstalling transformers-4.54.0:\n",
            "      Successfully uninstalled transformers-4.54.0\n",
            "Successfully installed Deprecated-1.2.18 about-time-4.2.1 alive-progress-3.3.0 backoff-2.2.1 bc-detect-secrets-1.5.43 bcrypt-4.3.0 chromadb-1.0.15 cma-4.3.0 coloredlogs-15.0.1 durationpy-0.10 faiss-cpu-1.11.0.post1 faker-37.4.2 ffmpeg-python-0.2.0 fuzzysearch-0.8.0 graphemeu-0.7.2 httptools-0.6.4 humanfriendly-10.0 json-repair-0.44.1 kubernetes-33.1.0 llm-guard-0.3.16 mmh3-5.2.0 networkx-3.4.2 ninja-1.11.1.4 nncf-2.17.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 openvino-2025.2.0 openvino-telemetry-2025.2.0 openvino-tokenizers-2025.2.0.1 optimum-1.26.1 optimum-intel-1.24.0 overrides-7.7.0 phonenumbers-8.13.55 posthog-5.4.0 presidio-analyzer-2.2.358 presidio-anonymizer-2.2.358 pybase64-1.4.2 pymoo-0.6.1.5 pypika-0.48.9 python-dotenv-1.1.1 requests-file-2.1.0 structlog-25.4.0 tldextract-5.3.0 transformers-4.51.3 unidiff-0.7.5 uvloop-0.21.0 watchfiles-1.1.0 yt-dlp-2025.7.21\n"
          ]
        }
      ],
      "source": [
        "!pip install openai google-generativeai faiss-cpu sentence-transformers python-dotenv \\\n",
        "            chromadb fastapi uvicorn aiohttp pydantic openvino optimum[openvino] \\\n",
        "            transformers nltk spacy diffusers llm-guard \\\n",
        "             yt-dlp huggingface_hub ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1ae73cc09933497b81a35f77359fa5b8",
            "2e3da4a954574e92994b2491e7ed3a06",
            "74cba72fb72a43e191f0a22c0a5c0243",
            "c0a65e63a9ce4d219c9b4527f6437ba0",
            "b5c455920a344961a04e42324ace049c",
            "81666028411d4ddd985feed0f396f524",
            "ff09004f58b24292a8d71a28f0c36853",
            "b3fe74b3d03a4309b1976e2e4d13d572",
            "ef1e1a811ad0488a8578300c1d3bd95c",
            "d123ba583099474eb33380d61919726e",
            "4e1a3ec22bc24536bb726504c85adcc7",
            "d3501fe42ce248b89b34626a7ca05755",
            "0ce7182f91c540bda7043879ef277319",
            "2d58958f3a5f4f2dadfcdde69c75fe29",
            "5ac46c5c593741cd9548f205e71476b4",
            "183778350de94bacb647051143f2298b",
            "fa06b2508a5e411aa74490ce2163f03e",
            "5c8cdee9154344fab2c3860d38f29e08",
            "fe2c36a31e13419a9c0785fa5d845f4c",
            "eb4fd6d6108046f18c358c4f33e123bb",
            "1c9ba03a594c4c189e80ece1cb7d9ee2",
            "84b4eb739fd44177a167a95518c87f3d",
            "0f011ab6fdb04ae09febd0116f87749e",
            "517c06e6945b44859e619e2d86a26705",
            "40323f6339f64da18820a698f3452332",
            "4bca5ad5f58548469cce90bd26ea9ee7",
            "96583d01ffee491db9d80c0f685e0422",
            "d1002a65dbf949dd9f547b7b9c9a7a7d",
            "d31246fa30754c9da7764c1bd1a30fde",
            "1db8cc13a47146279d40bba80565cf14",
            "0cdf0d40e0ed40c7b8b87c1671c73212",
            "087694d3be974e3ca43eeafb16168747",
            "660b5d480b554dfb9d388c7d260313aa",
            "f71bd4dc9ad84a7eb8e52b858c57e01a",
            "c81f437b8dba446ca721f6874fc4a8c0",
            "4ed40cc3465d4a71b5b8ce740e384bc0",
            "81fcdd14a9ff4c71bba4dc591ff980e2",
            "6f3d37ec903847e1a5680acdc4a58e00",
            "4eaa559453c249e3990374c831e102ad",
            "a120567118af4d789bea078d2f537c08",
            "23bce9a851c44a519d1130a76895341c",
            "a087909e9d9f49d9a6f072e9444c0fa9",
            "5af0a84d8d8a4feba26ec54fe9173f28",
            "19e15d5610dc450ebc8dfd3ecf85f206",
            "c682df8c95844d2eb257bf8085568bac",
            "96f56962f5c3448c8297abf594b308fa",
            "cc4f2ca92eab4c78992f802da65e07cc",
            "d44037f8d3674c87901d3c363eb27324",
            "7817160754bd47f6b1647763ea5e3eb1",
            "3df6f014107b4c0db134c3fdec4988b9",
            "464e756d47b241eeae334340bbae00c0",
            "c2585e7021c146f69bc56ed3cd166075",
            "2eb7998185d940e58812f956f516efcf",
            "9eef219a470f4cd2869932cbb76e6706",
            "a76f066a2a8f4e85b16a06baa75b71b7",
            "62324d86dee845a9bba2a57e624a1e4c",
            "0c5a22b88af9410196f65be091eeb873",
            "c0b25c3234f2407ab8fb22ffcc6fd369",
            "38f1d0bc95b748ee8d04d0a78215c9d1",
            "8d6c5706876b45a0ba12d99199fb6c8f",
            "7c94d194b9db4d58b28af6aaf82e2ee6",
            "a615484154c04082bff5f65005ba1816",
            "acd854b100fe499a9567836ffb50e48a",
            "5812276ed8b24059a4ec769125dc86a5",
            "8d6654f71c2a4b139d2e3f792e493677",
            "b4d3f09424ea4752b342b6c65db4ac61",
            "2e9b4d5ae3e64cfb8addd6846de58b50",
            "20e444327e4c4433893bbc2f9907bd5f",
            "6b94d6178aee4b8180f1631bcbfb67de",
            "d173aff5124446aa938589305b873beb",
            "363f2e7dcb094e9fad2953453d21eb8b",
            "1e737736d6124813817cc4ec31a0582b",
            "dedf0e363b074c018fb5d1714cc8d95b",
            "cff6a5c107844abe81b097eb881dac5f",
            "1dac2dedd5b24fec80a2e812d1a671d8",
            "ce73859887294c0dbec2b374e3c0cd56",
            "d2eaffb01d42440e92493b6c21242010",
            "1a8c118c77a2459fa13299124a45cfb6",
            "8ffbd78819904aa7ad21b5367e4cbf1c",
            "faa04040779942779e0b1f61e3a54fda",
            "5140801dd5a3418a839f5e95dd27caa4",
            "caeec708f69b494d9ab63b084de0b5df",
            "34b9cd74dcbd45abb0f30fde69735b09",
            "7a992eb207eb4b13bd97255eb9e53249",
            "60c6b71765c7408eb14b55043aa813f7",
            "2f4abb4131cf4f6abfe6ee2188378fa6",
            "697caffaee16455baab533dfa3fcd493",
            "125fdabfd76e496c9e94af92274ba117",
            "843d4f0941614df2b45388eef360fa3e",
            "012497113be64e78b61da9ebd83aa0c9",
            "2eef0002394a439ca27697012034796c",
            "241ca908c96e4ecabfc62910eb17bbb6",
            "881d6f1d8b3d4aee91b6e349103d83a9",
            "b1cbdf0530704d8ea3779ae0a4c7cf1c",
            "8b3a0c7f48e04415a61756396a11ba92",
            "cadf18da327f4ec69a28a889094e034f",
            "fca7c2360cdd4afe9e78f8e073919ee8",
            "78142e8f68644c419534f08c658dcc6c",
            "d8ef8bdb796c45e6a54b69ccbd3f2dd8",
            "1b007b2903934c02b2f1a3e593614b9c",
            "9557e27644634dc383166b04c9211295",
            "bb34fdd49e7a44a1b45bcf6e558c4838",
            "2cf9048d77bd4d5d96775c87bca3f8f6",
            "ba29857110fe47b8baaaaab7324163db",
            "f3017aec03d3418f8854dfbae940f193",
            "3f4084bf8ab14fadabcf7c5035559536",
            "83bf4133bd6b4ca294caf8db0f995969",
            "c04f17e32b26486e8b88b48ed5d21e70",
            "a17c6532089d49618e29c37d2a2336e3",
            "247dcf678e694b8da6dc810c097f6b1b",
            "711b9b1c4fe04bf48c552e51aa987bca",
            "b0bf78ab1aff4b1cb04b6d9a8b25d3cf",
            "90bd0bbdb3264a03a32c3f1773fbcec8",
            "f49dd5e4bb2b4e9781057ec25ef7619f",
            "0b01726282aa4dbd99ea2fc977e0c988",
            "b154ca64a4d6454889a78051934676c8",
            "d5b73c2af35049649a82f765f2f93a58",
            "cc310af465634127b01b737baaeafc9a",
            "3bef11a9cf854a3caeb03c503406d585",
            "43e8a47d722b422e89258e0695c791f6",
            "cb843a6024f946b0a33193ae167b738a"
          ]
        },
        "id": "YgyGhcfh8JLI",
        "outputId": "5ddbb7b7-64e9-436a-8f22-ed1e3f37cdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Multiple distributions found for package optimum. Picked distribution: optimum-intel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎓 LECTURE PROCESSING PIPELINE\n",
            "==================================================\n",
            "🔤 Enter YouTube URL or local file path: https://www.youtube.com/watch?v=P6FORpg0KVo\n",
            "🔑 Enter your OpenAI token: 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\n",
            "🚀 STARTING COMPLETE LECTURE PROCESSING PIPELINE\n",
            "============================================================\n",
            "📱 STEP 1: PROCESSING AUDIO & TRANSCRIPTION\n",
            "----------------------------------------\n",
            "🔧 Initializing Whisper model...\n",
            "🔁 Loading Whisper (OpenVINO)...\n",
            "Downloading and exporting model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ae73cc09933497b81a35f77359fa5b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3501fe42ce248b89b34626a7ca05755"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f011ab6fdb04ae09febd0116f87749e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f71bd4dc9ad84a7eb8e52b858c57e01a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c682df8c95844d2eb257bf8085568bac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62324d86dee845a9bba2a57e624a1e4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e9b4d5ae3e64cfb8addd6846de58b50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "normalizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a8c118c77a2459fa13299124a45cfb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "843d4f0941614df2b45388eef360fa3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b007b2903934c02b2f1a3e593614b9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "711b9b1c4fe04bf48c552e51aa987bca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper Small OpenVINO model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and processor loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257], 'forced_decoder_ids': [[1, None], [2, 50359]]}. If this is not desired, please set these values explicitly.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
            "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Transcription test successful!\n",
            "Test result: ' you' (should be empty/minimal for silence)\n",
            "🎧 Processing audio...\n",
            "🎬 Downloading from YouTube...\n",
            "🎧 Preprocessing audio...\n",
            "✅ Processed audio: processed_audio/How to Make Learning as Addictive as Social Media  Duolingos Luis Von Ahn  TED.wav\n",
            "📝 Starting transcription...\n",
            "📝 Loading audio from: processed_audio/How to Make Learning as Addictive as Social Media  Duolingos Luis Von Ahn  TED.wav\n",
            "Original sample rate: 16000, channels: 1\n",
            "Audio duration: 774.11 seconds\n",
            "🤖 Processing chunk 1...\n",
            "🤖 Processing chunk 2...\n",
            "🤖 Processing chunk 3...\n",
            "🤖 Processing chunk 4...\n",
            "🤖 Processing chunk 5...\n",
            "🤖 Processing chunk 6...\n",
            "🤖 Processing chunk 7...\n",
            "🤖 Processing chunk 8...\n",
            "🤖 Processing chunk 9...\n",
            "🤖 Processing chunk 10...\n",
            "🤖 Processing chunk 11...\n",
            "🤖 Processing chunk 12...\n",
            "🤖 Processing chunk 13...\n",
            "🤖 Processing chunk 14...\n",
            "🤖 Processing chunk 15...\n",
            "🤖 Processing chunk 16...\n",
            "🤖 Processing chunk 17...\n",
            "🤖 Processing chunk 18...\n",
            "🤖 Processing chunk 19...\n",
            "🤖 Processing chunk 20...\n",
            "🤖 Processing chunk 21...\n",
            "🤖 Processing chunk 22...\n",
            "🤖 Processing chunk 23...\n",
            "🤖 Processing chunk 24...\n",
            "🤖 Processing chunk 25...\n",
            "🤖 Processing chunk 26...\n",
            "\n",
            "==================================================\n",
            "✅ FINAL TRANSCRIPT:\n",
            "==================================================\n",
            "So, I'm from Guatemala. This is a public service announcement that is where Guatemala is. Also, that is not where they keep the prisoners. That is called Guantanamo. Not the same place. So Guatemala is right below Mexico. And for the Americans in the audience, and let this sink in, because it really applies in most ways, for the Americans in the audience, you can think of it as Mexico's It's a smaller country. It's a poorer country. And, well, what can I tell you? It has much better Mexican food. Guatemala is a very poor country. And a lot of people talk about education as something that brings equality to different social classes. But I always saw it as the opposite. And I think that's why I'm talking about the same thing. as some of them bring inequality. Because what happens in practice is that people who have a lot of money can by themselves be really good at education and therefore continue having a lot of money, whereas people who don't have very much money barely learn how to read and write and therefore never make a lot of money. And this is especially true in poor countries. Now, I was fortunate that I received a rich person's education, even though I didn't grow up rich. And it's because I'm an only child. And my mother, who was a single mother, spent all of her resources on my education. And this allowed me to come to college to the US and eventually get a PhD in computer science. Now, because of all of this, about 10 years ago, I decided I wanted to do something that would give equal access to education to everyone. Oh, by the way, this is what I want to talk to you about today, giving equal access to education to everyone. At the time, I was a professor of computer science at Carnegie Mellon University, and I decided to work on this with my PhD student, Severin. The way my brain works, all of education is just too general of a problem. So I decided, let's start by teaching one thing. And then I started thinking, okay, well, what should we teach first? Should we teach math? I mean, we both love math. Me and my co-founder, we both love math. And we didn't decide to do math. Then we started thinking, well, maybe we should teach computer science. But eventually, and this may be surprising to people in North America, eventually we decided that the best subject to start with and teaching foreign languages. And let me tell you why. There's a number of reasons. One of them is that there's a huge audience for it. There's about two billion people in the world learning a foreign language, both in school and outside of schools. Most of these people, by the way, are learning English. About 80% of them are learning English. In this weird map right here, all the countries in green are countries in which people are predominantly learning English. And the reason for that is because English can truly transform your life. In most countries in the world, knowledge of English to increase your income potential. So this is another reason why we decided to start with foreign languages, and it's because we can directly make more money if you learn another language, in particular English. And see, this is pretty different than many other subjects. For example, take math. And because of math, just knowledge of math does not increase your income potential, because usually you have to learn math to then learn physics, to then become a civil engineer, like that's how you make more money. Whereas with languages, if you were a waiter and you learned English, now you can be a waiter at a hotel and make more money. So we decided, well, let's get started by teaching languages. Now, we also convinced ourselves that the only way to really reach a lot of people was by using a mobile phone or a smartphone in particular. See, building schools all over the world is simply too expensive. On the other hand, most of the world's population already has access to a smartphone, and the trend is that that fraction is only going to increase. So we decided at the time that we would make a way to learn foreign languages mobile phone that was accessible to everyone. And then we called it Duolingo. Thank you. Now, in order to truly be accessible to everyone, rich and poor, Duolingo uses a freemium model to support itself. What that means is that you can learn as much as you want without ever having to pay. But if you don't pay, you may have to see an ad at the end of a lesson. Now, if you don't like ads, you can also pay to subscribe to turn off the ads. And it turns out that the best majority of the revenue for Duolingo comes from people who pay to subscribe to turn off the ads. Now, who are these people who pay to subscribe to turn off the ads? Well, they're usually people, well-off people, in rich countries like the US and Canada. Who are the people who don't pay to subscribe? They usually come from poorer countries like Brazil or Vietnam or Guatemala. So what I like about this model is that it is a small form of wealth redistribution, because we're basically getting the rich people education of everyone. So I like that. Yes. It's great. So with smartphones, we can reach a lot of people, and we can even get the rich people to pay for the whole thing. This is great. However, if you're trying to deliver education with a smartphone, you run into a humongous problem. And it is that smartphones come equipped with some of the most addictive drugs that humanity has ever engineered. TikTok, Instagram, mobile games. See, delivering education over a smartphone hoping that people will eat their broccoli, but right next to it, you put the most delicious dessert ever made. If you really want to deliver education to everyone, not only do you have to make it accessible, but also you have to make it so that people want to actually learn. And with Duolingo, we've been able to do this, and at the highest level, the way we've done this is by making the broccoli taste like dessert. I'll say it another way. What we've done is that we've used the same psychological techniques that apps like Instagram, TikTok, or mobile games used to keep people engaged. But in this case, we used them to keep people engaged, but with education. Let me give you some examples of these techniques. One of the most powerful ones is the notion of a streak. What a streak is, is just a counter that measures the number of days that you've used the product consecutively. You just take that number, you put it very prominently in your product, and then people come back every day. And the reason people come back every day is because Well, if they don't come back, that number resets to zero and people don't want to lose their streak. It works. Now, on the one side, streaks have been criticized for, for example, getting teens addicted to Snapchat. But in the case of an educational app, streaks get people to come back to study every day. Now, to give you an idea of the power of streaks, in the case of Duolingo, we have over 3 million daily active users that have a streak longer than 365. That means they haven't missed a day in the last year or longer. Now, one fact about streaks. What country do you think has the longest average streaks for an educational app? It's Japan. Of course. Shortest average streaks? Latin America, baby. But we're fun. Hey, we're fun. Another important mechanism to get people to come back to your problem are notifications. On the one side, notifications can be really spammy and annoying, but in the case of an educational product, people actually want to be reminded to learn. In the case of Duolingo, we have a very sophisticated AI system that basically chooses when to send a notification and also what to say in each notification to maximize the probability that people come back. Now, interestingly, even after all this sophistication, it turns out that the algorithm for choosing what time to send your notification is pretty simple. You know what is the best time to send people a notification? I'll tell you. It's 24 hours after they use the product last. Because there's an easy explanation. If you were free yesterday at 3 p.m., you're probably free today at 3 p.m. as well. So this is what a very sophisticated millions of dollars of AI found. It's funny. Now, with notifications, you shouldn't be spamming. And we're not spamming. With Duolingo, we actually stop sending notifications after seven days of inactivity. So if you don't use Duolingo for seven days, and stop sending you notifications. Now, at some point, it occurred to us, if we're stopping to send people notifications, we should let them know. So we started sending this notification to people saying, hey, these reminders don't seem to be working. We'll stop sending them for now. Do you know what people do when they get this notification? They come back! Passive, aggressive. Works for my mother, works for Duolingo. These passive-aggressive notifications are really good at getting people to come back because they feel like our green owl mascot has given up on them. So they come back. And speaking of our green owl mascot, by the way, because all our notifications come from our green owl mascot and, well, he's passive-aggressive and also pretty pushy, this has given rise to a lot of memes on the internet that make fun of just the great lengths that he will go through to get you back to learn a language. Here's one of my favorite ones. This is a meme. It's one of my favorite ones. It's basically, looks like you forgot your Spanish lessons, and then there's an intruder learned, presumably the owl broke into your house to give you a learning language. Now, Duolingo has entered the site, guys, and there's thousands of memes, there's SNL skits about it, and it's because we've managed to get people to want to learn a language by using the same techniques that mobile games and social media use to get people engaged. And this is a really important thing I don't actually believe that there's a way to make an educational app be as engaging as something like TikTok or Instagram or mobile games. But the good news is that, and by the way, the reason I don't believe that is because ultimately you have to teach people something, and it's hard to compete with cats and celebrities. But the good news is that I don't think you have to. See, here's the thing, when you're learning something, you get meaning out of it. Whereas when you're scrolling for two hours on Instagram, a lot of times, after a while, you feel like you just wasted your time. So I think it's actually okay if your educational product is only 80 or 90% as engaging as something like TikTok, because the other 10 or 20% will be provided by people's internal motivation, though of course not much more than that. This is really a key point. If we want to get people to do something meaningful, you can use the same techniques that apps like social media use to get people to do it. And even if you're not as engaging as those apps are, you can still get hundreds of millions of people to use your product. In the case of Duolingo, for example, there are more people learning languages on Duolingo in the United States than there are people learning languages across all U.S. high schools combined. And this is true in most countries in the world. My hope is that, I know we can do this, but my hope is that as humanity we can do what Duolingo has done for learning languages for all other subjects, where we can get people to learn math with mobile phones like millions of people to learn math with mobile phones or physics or whatever. I hope for a future in which screen time is not a bad thing, in which we can deliver high-quality education to everyone, rich or poor, using a mobile phone. But the single most important thing that I can end this talk with is a reminder to please, pretty please, I beg you, do your language lessons today. Thank you very much. Thank you. Louise, thank you so much. Thank you. I wonder if you can just say a little bit more about that last point, about how do you think that you can apply this type of thinking to other subjects? So you mentioned math, you mentioned things like that. How do you do that? Yeah, I think in particular, subjects that are learned through repetition. And it turns out most things that are really meaningful are learned through thousands and thousands of repetitions. You learn to read. To repetition, you learn elementary school math to repetition. Most things that you can learn to repetition, you can actually gamify and turn into something like Duolingo, where people just do it a lot and do it fun. It's a little harder for things like explanations. That's probably going to require some really good videos. Sal Khan is doing a really good job with that. But for things that require a lot of repetition, I think we can use the same methods. Thank you so much for sharing your time.\n",
            "==================================================\n",
            "\n",
            "💾 Transcript saved at: processed_audio/How to Make Learning as Addictive as Social Media  Duolingos Luis Von Ahn  TED_transcript.txt\n",
            "✅ Transcription completed!\n",
            "📝 Transcript: processed_audio/How to Make Learning as Addictive as Social Media  Duolingos Luis Von Ahn  TED_transcript.txt\n",
            "🎵 Processed audio: processed_audio/How to Make Learning as Addictive as Social Media  Duolingos Luis Von Ahn  TED.wav\n",
            "😴 Sleeping for 15 seconds...\n",
            "\n",
            "🧠 STEP 2: IDENTIFYING KEY TOPICS FROM TRANSCRIPT\n",
            "----------------------------------------\n",
            "🔍 IDENTIFYING TOPICS FROM TRANSCRIPT...\n",
            "----------------------------------------\n",
            "📄 Transcript split into 2 chunks for topic identification\n",
            "🔍 Identifying topics in chunk 1/2...\n",
            "✅ Topics identified for chunk 1\n",
            "🔍 Identifying topics in chunk 2/2...\n",
            "✅ Topics identified for chunk 2\n",
            "🔗 Consolidating and organizing topics...\n",
            "✅ Topics identification completed!\n",
            "📋 Topics saved to: processed_audio/identified_topics.txt\n",
            "🔢 Processed 2 chunks\n",
            "✅ Topics identified and saved to: /content/processed_audio/identified_topics.txt\n",
            "😴 Sleeping for 15 seconds...\n",
            "\n",
            "📚 STEP 3: GENERATING DETAILED NOTES\n",
            "----------------------------------------\n",
            "📚 Generating notes from transcript: processed_audio/How to Make Learning as Addictive as Social Media  Duolingos Luis Von Ahn  TED_transcript.txt\n",
            "📋 Using topics from: /content/processed_audio/identified_topics.txt\n",
            "📁 Output directory: processed_audio\n",
            "📊 ENHANCED TOKEN MANAGEMENT:\n",
            "   Total transcript tokens: 3220\n",
            "   Optimal chunks: 8\n",
            "   Max input tokens per chunk: 6000\n",
            "   Max output tokens per chunk: 4700\n",
            "   Estimated total API calls: 11\n",
            "📄 Transcript split into 7 chunks\n",
            "🔄 Processing chunk 1/7... (Tokens: 505)\n",
            "   Adjusted max output to: 4072\n",
            "   Input tokens: 3628, Max output: 4072\n",
            "✅ Chunk 1 completed (4408 tokens generated)\n",
            "🔄 Processing chunk 2/7... (Tokens: 520)\n",
            "   Adjusted max output to: 4057\n",
            "   Input tokens: 3643, Max output: 4057\n",
            "✅ Chunk 2 completed (2698 tokens generated)\n",
            "🔄 Processing chunk 3/7... (Tokens: 501)\n",
            "   Adjusted max output to: 4076\n",
            "   Input tokens: 3624, Max output: 4076\n",
            "✅ Chunk 3 completed (2888 tokens generated)\n",
            "🔄 Processing chunk 4/7... (Tokens: 509)\n",
            "   Adjusted max output to: 4068\n",
            "   Input tokens: 3632, Max output: 4068\n",
            "✅ Chunk 4 completed (2570 tokens generated)\n",
            "🔄 Processing chunk 5/7... (Tokens: 524)\n",
            "   Adjusted max output to: 4053\n",
            "   Input tokens: 3647, Max output: 4053\n",
            "✅ Chunk 5 completed (2413 tokens generated)\n",
            "🔄 Processing chunk 6/7... (Tokens: 529)\n",
            "   Adjusted max output to: 4048\n",
            "   Input tokens: 3652, Max output: 4048\n",
            "✅ Chunk 6 completed (3755 tokens generated)\n",
            "🔄 Processing chunk 7/7... (Tokens: 129)\n",
            "   Adjusted max output to: 4448\n",
            "   Input tokens: 3252, Max output: 4448\n",
            "✅ Chunk 7 completed (3238 tokens generated)\n",
            "🔗 Creating integrated final notes...\n",
            "📝 Large content detected - creating comprehensive integration...\n",
            "⚠️  Integration failed: Error code: 413 - {'error': {'code': 'tokens_limit_reached', 'message': 'Request body too large for gpt-4.1 model. Max size: 8000 tokens.', 'details': 'Request body too large for gpt-4.1 model. Max size: 8000 tokens.'}}\n",
            "📝 Individual chunk notes saved to: processed_audio/individual_chunk_notes.md\n",
            "📖 Final integrated notes saved to: processed_audio/detailed_exam_ready_notes.md\n",
            "📚 Generating comprehensive study guide...\n",
            "📋 Comprehensive study guide saved to: processed_audio/comprehensive_study_guide.md\n",
            "\n",
            "🎉 Enhanced processing complete! Generated 7 chunk notes + integrated final notes + comprehensive study guide\n",
            "📊 Token utilization: Used approximately 11 API calls with enhanced token limits\n",
            "✅ Notes generation completed!\n",
            "😴 Sleeping for 15 seconds...\n",
            "\n",
            "============================================================\n",
            "🎉 PIPELINE COMPLETED SUCCESSFULLY!\n",
            "============================================================\n",
            "📁 Output Directory: processed_audio\n",
            "📝 Transcript: processed_audio/How to Make Learning as Addictive as Social Media  Duolingos Luis Von Ahn  TED_transcript.txt\n",
            "📖 Final Notes: processed_audio/detailed_exam_ready_notes.md\n",
            "📋 Study Guide: processed_audio/comprehensive_study_guide.md\n",
            "📊 Individual Chunks: processed_audio/individual_chunk_notes.md\n",
            "🎵 Processed Audio: processed_audio/How to Make Learning as Addictive as Social Media  Duolingos Luis Von Ahn  TED.wav\n",
            "🔢 Chunks Processed: 7\n",
            "============================================================\n",
            "\n",
            "🎉 SUCCESS! All files are ready for studying.\n",
            "📚 Check your notes at: processed_audio/detailed_exam_ready_notes.md\n"
          ]
        }
      ],
      "source": [
        "# ✅ COMPLETE LECTURE PROCESSING PIPELINE\n",
        "# Integrates: Audio Processing + Transcription + Topic Identification + Notes Generation\n",
        "\n",
        "import os, re, tempfile, subprocess, torch, torchaudio\n",
        "from pathlib import Path\n",
        "from transformers import AutoProcessor, AutoTokenizer\n",
        "from optimum.intel.openvino import OVModelForSeq2SeqLM, OVModelForSpeechSeq2Seq\n",
        "import yt_dlp\n",
        "import warnings\n",
        "from transformers import WhisperProcessor, WhisperTokenizer, WhisperFeatureExtractor, WhisperTokenizerFast\n",
        "from openai import OpenAI\n",
        "import tiktoken\n",
        "import time\n",
        "\n",
        "# ✅ DIRECTORIES\n",
        "UPLOAD_FOLDER = \"uploads\"\n",
        "MODEL_CACHE = \"model_cache\"\n",
        "PROCESSED_AUDIO_DIR = \"processed_audio\"\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(MODEL_CACHE, exist_ok=True)\n",
        "os.makedirs(PROCESSED_AUDIO_DIR, exist_ok=True)\n",
        "\n",
        "# ✅ GLOBAL VARIABLES (will be initialized)\n",
        "whisper_model = None\n",
        "processor = None\n",
        "device = None\n",
        "\n",
        "# ✅ TRANSCRIPTION FUNCTIONS (UNCHANGED)\n",
        "def initialize_whisper_model():\n",
        "    global whisper_model, processor, device\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    print(\"🔁 Loading Whisper (OpenVINO)...\")\n",
        "    whisper_model_path = os.path.join(MODEL_CACHE, \"whisper-small-ov\")\n",
        "\n",
        "    if not os.path.exists(whisper_model_path):\n",
        "        print(\"Downloading and exporting model...\")\n",
        "        whisper_model = OVModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-small\", export=True)\n",
        "        whisper_model.save_pretrained(whisper_model_path)\n",
        "        print(\"Whisper Small OpenVINO model saved!\")\n",
        "    else:\n",
        "        print(\"Loading existing Whisper Small OpenVINO model...\")\n",
        "        whisper_model = OVModelForSpeechSeq2Seq.from_pretrained(whisper_model_path)\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Initialize processor components\n",
        "    tokenizer = WhisperTokenizerFast.from_pretrained(\"openai/whisper-small\")\n",
        "    feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
        "    processor = WhisperProcessor(\n",
        "        tokenizer=WhisperTokenizer.from_pretrained(\"openai/whisper-small\"),\n",
        "        feature_extractor=feature_extractor\n",
        "    )\n",
        "\n",
        "    print(\"✅ Model and processor loaded successfully\")\n",
        "    return True\n",
        "\n",
        "class AudioPreprocessor:\n",
        "    def __init__(self, output_dir=\"processed_audio\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def is_youtube_url(self, input_path):\n",
        "        youtube_patterns = [\n",
        "            r'(?:https?://)?(?:www\\.)?youtube\\.com/watch\\?v=[\\w-]+',\n",
        "            r'(?:https?://)?(?:www\\.)?youtu\\.be/[\\w-]+'\n",
        "        ]\n",
        "        return any(re.match(pattern, input_path) for pattern in youtube_patterns)\n",
        "\n",
        "    def download_youtube_audio(self, url, temp_dir):\n",
        "        output_path = os.path.join(temp_dir, \"%(title)s.%(ext)s\")\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'outtmpl': output_path,\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(url, download=True)\n",
        "            title = re.sub(r'[^\\w\\s-]', '', info.get('title', 'audio')).strip()\n",
        "            for file in os.listdir(temp_dir):\n",
        "                if file.endswith(('.wav', '.webm', '.m4a', '.mp3', '.opus')):\n",
        "                    return os.path.join(temp_dir, file), title\n",
        "        return None, None\n",
        "\n",
        "    def preprocess_audio(self, input_file, output_file):\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', input_file,\n",
        "            '-af', 'highpass=f=200,lowpass=f=3000,afftdn=nf=-25',\n",
        "            '-ar', '16000', '-ac', '1',\n",
        "            '-c:a', 'pcm_s16le', '-y', output_file\n",
        "        ]\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "        if result.returncode != 0:\n",
        "            raise Exception(f\"FFmpeg error: {result.stderr}\")\n",
        "\n",
        "    def process(self, input_path, output_filename=None):\n",
        "        with tempfile.TemporaryDirectory() as temp_dir:\n",
        "            if self.is_youtube_url(input_path):\n",
        "                print(\"🎬 Downloading from YouTube...\")\n",
        "                audio_file, title = self.download_youtube_audio(input_path, temp_dir)\n",
        "                if not audio_file:\n",
        "                    raise Exception(\"Failed to download YouTube audio\")\n",
        "                if not output_filename:\n",
        "                    output_filename = f\"{title}.wav\"\n",
        "            else:\n",
        "                print(\"📂 Processing local file...\")\n",
        "                if not os.path.exists(input_path):\n",
        "                    raise FileNotFoundError(f\"File not found: {input_path}\")\n",
        "                audio_file = input_path\n",
        "                if not output_filename:\n",
        "                    base_name = Path(input_path).stem\n",
        "                    output_filename = f\"{base_name}_processed.wav\"\n",
        "\n",
        "            if not output_filename.endswith('.wav'):\n",
        "                output_filename += '.wav'\n",
        "\n",
        "            output_path = self.output_dir / output_filename\n",
        "            print(\"🎧 Preprocessing audio...\")\n",
        "            self.preprocess_audio(audio_file, str(output_path))\n",
        "            print(f\"✅ Processed audio: {output_path}\")\n",
        "            return str(output_path)\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Main transcription function\"\"\"\n",
        "    global whisper_model, processor\n",
        "\n",
        "    if whisper_model is None or processor is None:\n",
        "        raise Exception(\"Model not initialized. Call initialize_whisper_model() first.\")\n",
        "\n",
        "    print(f\"📝 Loading audio from: {audio_path}\")\n",
        "\n",
        "    try:\n",
        "        # Load and preprocess audio\n",
        "        waveform, sr = torchaudio.load(audio_path)\n",
        "        print(f\"Original sample rate: {sr}, channels: {waveform.shape[0]}\")\n",
        "\n",
        "        # Convert to mono if stereo\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # Resample to 16kHz if needed\n",
        "        if sr != 16000:\n",
        "            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
        "\n",
        "        # Prepare inputs for the model\n",
        "        audio_array = waveform.squeeze().numpy()\n",
        "        print(f\"Audio duration: {len(audio_array)/16000:.2f} seconds\")\n",
        "\n",
        "        # Process audio in chunks if it's too long\n",
        "        chunk_length = 30 * 16000  # 30 seconds\n",
        "        transcripts = []\n",
        "\n",
        "        for i in range(0, len(audio_array), chunk_length):\n",
        "            chunk = audio_array[i:i + chunk_length]\n",
        "            inputs = processor(chunk, sampling_rate=16000, return_tensors=\"pt\")\n",
        "\n",
        "            print(f\"🤖 Processing chunk {i//chunk_length + 1}...\")\n",
        "\n",
        "            # Generate transcription with optimized parameters\n",
        "            with torch.no_grad():\n",
        "                predicted_ids = whisper_model.generate(\n",
        "                    inputs[\"input_features\"],\n",
        "                    max_new_tokens=444,\n",
        "                    do_sample=False,\n",
        "                    temperature=0.0,\n",
        "                    return_dict_in_generate=False,\n",
        "                    use_cache=True\n",
        "                )\n",
        "\n",
        "            # Decode the transcription\n",
        "            chunk_transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "            if chunk_transcription.strip():\n",
        "                transcripts.append(chunk_transcription.strip())\n",
        "\n",
        "        # Combine all transcripts\n",
        "        full_transcript = \" \".join(transcripts)\n",
        "\n",
        "        if not full_transcript.strip():\n",
        "            return \"No speech detected in the audio.\"\n",
        "\n",
        "        return full_transcript.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return f\"Transcription failed: {str(e)}\"\n",
        "\n",
        "def test_transcription_setup():\n",
        "    \"\"\"Test if the model and processor are properly set up\"\"\"\n",
        "    global whisper_model, processor\n",
        "\n",
        "    try:\n",
        "        # Create dummy audio (1 second of silence at 16kHz)\n",
        "        dummy_audio = torch.zeros(16000)\n",
        "        # Process with the processor\n",
        "        inputs = processor(\n",
        "            dummy_audio.numpy(),\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        # Test generation\n",
        "        with torch.no_grad():\n",
        "            predicted_ids = whisper_model.generate(\n",
        "                inputs[\"input_features\"],\n",
        "                max_length=10,  # Short for testing\n",
        "                num_beams=1,\n",
        "                do_sample=False,\n",
        "            )\n",
        "        # Decode\n",
        "        transcription = processor.batch_decode(\n",
        "            predicted_ids,\n",
        "            skip_special_tokens=True\n",
        "        )[0]\n",
        "        print(\"✅ Transcription test successful!\")\n",
        "        print(f\"Test result: '{transcription}' (should be empty/minimal for silence)\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Transcription test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def complete_transcription(input_source, output_filename=None, save_transcript=True):\n",
        "    \"\"\"Complete end-to-end transcription function\"\"\"\n",
        "    global whisper_model, processor\n",
        "\n",
        "    # Initialize model if not already done\n",
        "    if whisper_model is None or processor is None:\n",
        "        print(\"🔧 Initializing Whisper model...\")\n",
        "        initialize_whisper_model()\n",
        "        test_transcription_setup()\n",
        "\n",
        "    # Initialize audio preprocessor\n",
        "    pre = AudioPreprocessor(output_dir=PROCESSED_AUDIO_DIR)\n",
        "\n",
        "    try:\n",
        "        # Process audio\n",
        "        print(\"🎧 Processing audio...\")\n",
        "        processed_path = pre.process(input_source, output_filename)\n",
        "\n",
        "        # Transcribe\n",
        "        print(\"📝 Starting transcription...\")\n",
        "        transcript = transcribe_audio(processed_path)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"✅ FINAL TRANSCRIPT:\")\n",
        "        print(\"=\"*50)\n",
        "        print(transcript)\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        result = {\n",
        "            'transcript': transcript,\n",
        "            'processed_audio_path': processed_path,\n",
        "            'transcript_path': None\n",
        "        }\n",
        "\n",
        "        # Save transcript if requested\n",
        "        if save_transcript:\n",
        "            save_path = processed_path.replace(\".wav\", \"_transcript.txt\")\n",
        "            with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(transcript)\n",
        "            print(f\"\\n💾 Transcript saved at: {save_path}\")\n",
        "            result['transcript_path'] = save_path\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERROR: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "\n",
        "# ✅ NOTES GENERATION FUNCTIONS (UNCHANGED)\n",
        "def count_tokens(text, model='openai/gpt-4.1'):\n",
        "    \"\"\"Count tokens in text using tiktoken\"\"\"\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model)\n",
        "        return len(encoding.encode(text))\n",
        "    except:\n",
        "        # Fallback approximation: ~4 characters per token\n",
        "        return len(text) // 4\n",
        "\n",
        "def chunk_transcript(transcript_text, topics_text, max_tokens=3000):\n",
        "    \"\"\"\n",
        "    Chunk transcript intelligently while keeping topics intact\n",
        "    max_tokens is set lower than 4k to leave room for the system prompt\n",
        "    \"\"\"\n",
        "    # Split transcript into sentences for better chunking\n",
        "    sentences = transcript_text.replace('\\n', ' ').split('. ')\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    topics_tokens = count_tokens(topics_text)\n",
        "\n",
        "    # Reserve tokens for system prompt (estimated ~1000 tokens)\n",
        "    available_tokens = max_tokens - topics_tokens - 1000\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip() + '. '\n",
        "        sentence_tokens = count_tokens(sentence)\n",
        "        current_chunk_tokens = count_tokens(current_chunk)\n",
        "\n",
        "        if current_chunk_tokens + sentence_tokens < available_tokens:\n",
        "            current_chunk += sentence\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "\n",
        "    # Add the last chunk if it exists\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def chunk_text(text, chunk_size=7500):\n",
        "    \"\"\"Split text into chunks of given size.\"\"\"\n",
        "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def identify_topics_from_transcript(transcript_path,\n",
        "                                  token=\"your_token_here\",\n",
        "                                  endpoint=\"https://models.github.ai/inference\",\n",
        "                                  model=\"meta/Llama-4-Scout-17B-16E-Instruct\",\n",
        "                                  output_file=\"identified_topics.txt\"):\n",
        "    \"\"\"\n",
        "    ✅ ENHANCED TOPIC IDENTIFICATION FUNCTION\n",
        "    Automatically identifies topics from transcript and returns the topics file path\n",
        "    \"\"\"\n",
        "    print(\"🔍 IDENTIFYING TOPICS FROM TRANSCRIPT...\")\n",
        "    print(\"-\"*40)\n",
        "\n",
        "    # Read the transcript file\n",
        "    with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        transcript_text = f.read()\n",
        "\n",
        "    # Chunk the transcript\n",
        "    chunks = chunk_text(transcript_text, chunk_size=7500)\n",
        "    print(f\"📄 Transcript split into {len(chunks)} chunks for topic identification\")\n",
        "\n",
        "    # Set up OpenAI client\n",
        "    client = OpenAI(\n",
        "        base_url=endpoint,\n",
        "        api_key=token,\n",
        "    )\n",
        "\n",
        "    # Collect identified topics\n",
        "    all_topics = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"🔍 Identifying topics in chunk {i+1}/{len(chunks)}...\")\n",
        "        response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"You are an expert academic assistant. Identify the key topics, concepts, and subjects covered in this transcript chunk. \"\n",
        "                        \"Focus on:\\n\"\n",
        "                        \"- Main concepts and theories discussed\\n\"\n",
        "                        \"- Technical terms and definitions\\n\"\n",
        "                        \"- Mathematical formulas or equations mentioned\\n\"\n",
        "                        \"- Practical applications or examples\\n\"\n",
        "                        \"- Key learning objectives\\n\\n\"\n",
        "                        \"Format your response as a clear list of topics with brief descriptions. \"\n",
        "                        \"Do not hallucinate or include irrelevant topics. Only identify what is actually discussed in the text.\\n\\n\"\n",
        "                        f\"TRANSCRIPT CHUNK:\\n{chunk}\"\n",
        "                    ),\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            top_p=1.0,\n",
        "            model=model,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "\n",
        "        result = response.choices[0].message.content.strip()\n",
        "        all_topics.append(f\"### Chunk {i+1} Topics:\\n{result}\\n\")\n",
        "        print(f\"✅ Topics identified for chunk {i+1}\")\n",
        "\n",
        "    # Combine all topics and create final consolidated list\n",
        "    print(\"🔗 Consolidating and organizing topics...\")\n",
        "\n",
        "    consolidation_prompt = f\"\"\"You are an expert academic assistant. You have been provided with topic lists from different chunks of the same lecture transcript.\n",
        "\n",
        "Your task is to:\n",
        "1. Consolidate and organize all topics into a coherent structure\n",
        "2. Remove duplicate or overlapping topics\n",
        "3. Group related topics together\n",
        "4. Create a hierarchical organization of main topics and subtopics\n",
        "5. Ensure the final list covers all important concepts from the lecture\n",
        "\n",
        "Here are the individual chunk topics to consolidate:\n",
        "\n",
        "{chr(10).join(all_topics)}\n",
        "\n",
        "Create a final organized list of key topics that should be covered in detailed lecture notes. Format as a clear, structured list.\"\"\"\n",
        "\n",
        "    consolidation_response = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": consolidation_prompt,\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        model=model,\n",
        "        max_tokens=1500\n",
        "    )\n",
        "\n",
        "    consolidated_topics = consolidation_response.choices[0].message.content.strip()\n",
        "\n",
        "    # Save consolidated topics to file\n",
        "    output_path = os.path.join(os.path.dirname(transcript_path), output_file)\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"# IDENTIFIED KEY TOPICS FOR LECTURE NOTES\\n\\n\")\n",
        "        f.write(\"## Individual Chunk Analysis:\\n\")\n",
        "        f.write(\"\\n\".join(all_topics))\n",
        "        f.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "        f.write(\"## CONSOLIDATED FINAL TOPICS:\\n\")\n",
        "        f.write(consolidated_topics)\n",
        "\n",
        "    print(f\"✅ Topics identification completed!\")\n",
        "    print(f\"📋 Topics saved to: {output_path}\")\n",
        "    print(f\"🔢 Processed {len(chunks)} chunks\")\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def calculate_optimal_chunking(transcript_text, topics_text, max_tokens_per_call=7500, max_calls_per_day=50):\n",
        "    \"\"\"\n",
        "    Calculate optimal chunking strategy with fixed 8-10 chunks regardless of content length\n",
        "    \"\"\"\n",
        "    # Base system prompt tokens\n",
        "    base_system_tokens = 4000  # Reduced for safety\n",
        "    topics_tokens = count_tokens(topics_text)\n",
        "    transcript_tokens = count_tokens(transcript_text)\n",
        "\n",
        "    # Fixed chunk strategy: always use 8-10 chunks\n",
        "    # Choose based on transcript length for optimal distribution\n",
        "    if transcript_tokens < 5000:\n",
        "        optimal_chunks = 8\n",
        "    elif transcript_tokens < 15000:\n",
        "        optimal_chunks = 9\n",
        "    else:\n",
        "        optimal_chunks = 10\n",
        "\n",
        "    # System overhead (prompt + topics)\n",
        "    system_overhead = base_system_tokens + topics_tokens\n",
        "\n",
        "    # Safe token limits with buffer\n",
        "    max_safe_input = 5000  # Safe input limit per chunk\n",
        "    max_safe_output = 4000  # Safe output limit per chunk\n",
        "\n",
        "    # Ensure we don't exceed model limits\n",
        "    total_per_call = system_overhead + max_safe_input + max_safe_output\n",
        "    if total_per_call > max_tokens_per_call:\n",
        "        # Adjust if still too large\n",
        "        max_safe_input = 6000\n",
        "        max_safe_output = 4700\n",
        "\n",
        "    return {\n",
        "        'optimal_chunks': optimal_chunks,\n",
        "        'max_input_tokens_per_chunk': max_safe_input,\n",
        "        'max_output_tokens_per_chunk': max_safe_output,\n",
        "        'total_transcript_tokens': transcript_tokens,\n",
        "        'system_overhead_tokens': system_overhead,\n",
        "        'estimated_total_calls': optimal_chunks + 3\n",
        "    }\n",
        "\n",
        "def smart_chunk_transcript(transcript_text, max_tokens_per_chunk):\n",
        "    \"\"\"\n",
        "    Intelligently chunk transcript into exactly the specified number of chunks\n",
        "    \"\"\"\n",
        "    # Calculate total tokens and determine chunk count from the chunking strategy\n",
        "    total_tokens = count_tokens(transcript_text)\n",
        "\n",
        "    # Split by sentences for better coherence\n",
        "    sentences = []\n",
        "    current_sentence = \"\"\n",
        "\n",
        "    # Simple sentence splitting\n",
        "    for char in transcript_text:\n",
        "        current_sentence += char\n",
        "        if char in '.!?' and len(current_sentence.strip()) > 20:\n",
        "            sentences.append(current_sentence.strip())\n",
        "            current_sentence = \"\"\n",
        "\n",
        "    # Add remaining text\n",
        "    if current_sentence.strip():\n",
        "        sentences.append(current_sentence.strip())\n",
        "\n",
        "    # If we have very few sentences, split by paragraphs or fixed length\n",
        "    if len(sentences) < 8:\n",
        "        # Fallback: split into fixed-size chunks\n",
        "        words = transcript_text.split()\n",
        "        chunk_size = len(words) // 8  # Aim for 8 chunks minimum\n",
        "        sentences = []\n",
        "        for i in range(0, len(words), chunk_size):\n",
        "            chunk_words = words[i:i + chunk_size]\n",
        "            sentences.append(' '.join(chunk_words))\n",
        "\n",
        "    # Now distribute sentences across target number of chunks\n",
        "    target_chunks = 8 if total_tokens < 10000 else (9 if total_tokens < 20000 else 10)\n",
        "    sentences_per_chunk = max(1, len(sentences) // target_chunks)\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    sentence_count = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        current_chunk += sentence + \" \"\n",
        "        sentence_count += 1\n",
        "\n",
        "        # Check if we should close this chunk\n",
        "        chunk_tokens = count_tokens(current_chunk)\n",
        "\n",
        "        if (sentence_count >= sentences_per_chunk and chunk_tokens > 500) or chunk_tokens >= max_tokens_per_chunk:\n",
        "            if current_chunk.strip():\n",
        "                chunks.append(current_chunk.strip())\n",
        "                current_chunk = \"\"\n",
        "                sentence_count = 0\n",
        "\n",
        "    # Add remaining content\n",
        "    if current_chunk.strip():\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    # Ensure we have the right number of chunks by merging small ones\n",
        "    while len(chunks) > target_chunks:\n",
        "        # Find the smallest chunk and merge it with the next one\n",
        "        smallest_idx = min(range(len(chunks)), key=lambda i: len(chunks[i]))\n",
        "        if smallest_idx < len(chunks) - 1:\n",
        "            chunks[smallest_idx] += \" \" + chunks[smallest_idx + 1]\n",
        "            chunks.pop(smallest_idx + 1)\n",
        "        else:\n",
        "            chunks[smallest_idx - 1] += \" \" + chunks[smallest_idx]\n",
        "            chunks.pop(smallest_idx)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def generate_detailed_notes(transcription_result, topics_path, output_dir=None,\n",
        "                          token=\"your_token_here\", endpoint=\"https://models.github.ai/inference\",\n",
        "                          model=\"openai/gpt-4.1\"):\n",
        "    \"\"\"Generate detailed exam-ready notes with improved completeness and code examples.\"\"\"\n",
        "\n",
        "    # Extract transcript path from result\n",
        "    transcript_path = transcription_result['transcript_path']\n",
        "\n",
        "    if not transcript_path or not os.path.exists(transcript_path):\n",
        "        raise FileNotFoundError(f\"Transcript file not found: {transcript_path}\")\n",
        "\n",
        "    if not os.path.exists(topics_path):\n",
        "        raise FileNotFoundError(f\"Topics file not found: {topics_path}\")\n",
        "\n",
        "    # Set output directory\n",
        "    if output_dir is None:\n",
        "        output_dir = os.path.dirname(transcript_path)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"📚 Generating notes from transcript: {transcript_path}\")\n",
        "    print(f\"📋 Using topics from: {topics_path}\")\n",
        "    print(f\"📁 Output directory: {output_dir}\")\n",
        "\n",
        "    # Read transcript and topics\n",
        "    with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        transcript_text = f.read()\n",
        "\n",
        "    with open(topics_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        identified_topics = f.read()\n",
        "\n",
        "    # Calculate optimal chunking strategy\n",
        "    chunking_strategy = calculate_optimal_chunking(transcript_text, identified_topics)\n",
        "\n",
        "    print(f\"📊 ENHANCED TOKEN MANAGEMENT:\")\n",
        "    print(f\"   Total transcript tokens: {chunking_strategy['total_transcript_tokens']}\")\n",
        "    print(f\"   Optimal chunks: {chunking_strategy['optimal_chunks']}\")\n",
        "    print(f\"   Max input tokens per chunk: {chunking_strategy['max_input_tokens_per_chunk']}\")\n",
        "    print(f\"   Max output tokens per chunk: {chunking_strategy['max_output_tokens_per_chunk']}\")\n",
        "    print(f\"   Estimated total API calls: {chunking_strategy['estimated_total_calls']}\")\n",
        "\n",
        "    # OpenAI configuration\n",
        "    client = OpenAI(\n",
        "        base_url=endpoint,\n",
        "        api_key=token,\n",
        "    )\n",
        "\n",
        "    # Smart chunk the transcript\n",
        "    transcript_chunks = smart_chunk_transcript(\n",
        "        transcript_text,\n",
        "        chunking_strategy['max_input_tokens_per_chunk']\n",
        "    )\n",
        "\n",
        "    print(f\"📄 Transcript split into {len(transcript_chunks)} chunks\")\n",
        "\n",
        "    # ENHANCED base system prompt with code emphasis and completion instructions\n",
        "    base_system_prompt = f\"\"\"You are an expert academic assistant and technical writer specializing in computer science, machine learning, and technical subjects. Your task is to create DETAILED, COMPREHENSIVE, EXAM-READY notes that enable deep understanding and successful exam performance.\n",
        "\n",
        "**IDENTIFIED KEY TOPICS TO FOCUS ON:**\n",
        "{identified_topics}\n",
        "\n",
        "**CRITICAL REQUIREMENTS FOR DETAILED NOTES:**\n",
        "\n",
        "1. **COMPLETE COVERAGE**: You MUST cover ALL concepts mentioned in the transcript chunk thoroughly. Do NOT stop abruptly or leave topics incomplete. Ensure every important concept gets full explanation.\n",
        "\n",
        "2. **CODE EXAMPLES MANDATORY**: For any computer science, programming, machine learning, or technical topics:\n",
        "   - Provide complete, working code examples\n",
        "   - Include step-by-step code explanations\n",
        "   - Show multiple implementation approaches when relevant\n",
        "   - Add comments explaining each line of complex code\n",
        "   - Include practical examples that students can run\n",
        "   - Demonstrate best practices and common patterns\n",
        "   - Show error handling and edge cases\n",
        "\n",
        "3. **DEPTH OVER BREVITY**: Create detailed explanations, not summaries. Each concept should be explained thoroughly enough that a student can understand it completely from your notes alone.\n",
        "\n",
        "4. **EXAM-READY CONTENT**: Structure content so students can:\n",
        "   - Answer conceptual questions confidently\n",
        "   - Solve mathematical problems step-by-step\n",
        "   - Write and explain code implementations\n",
        "   - Compare and contrast different approaches\n",
        "   - Apply concepts to new scenarios\n",
        "\n",
        "5. **DUAL-LEVEL EXPLANATIONS**: For every concept, provide:\n",
        "   - **Intuitive/Primitive Explanation**: Simple, everyday language with analogies\n",
        "   - **Technical/Mathematical Explanation**: Precise definitions, formulas, mathematical rigor\n",
        "   - **Implementation Details**: Code examples and practical applications\n",
        "   - **Bridge Between All Levels**: Show how intuitive connects to technical to implementation\n",
        "\n",
        "6. **COMPREHENSIVE EXAMPLES**: Include:\n",
        "   - Step-by-step worked examples with detailed explanations\n",
        "   - Multiple examples per concept (simple → complex)\n",
        "   - Common exam-style problems and solutions\n",
        "   - Real-world applications with specific implementations\n",
        "   - Code examples with line-by-line explanations\n",
        "   - Algorithm implementations with complexity analysis\n",
        "\n",
        "7. **MATHEMATICAL AND ALGORITHMIC RIGOR**: For all formulas, algorithms, and code:\n",
        "   - Derive from first principles when possible\n",
        "   - Explain each variable, parameter, and function\n",
        "   - Show step-by-step mathematical manipulations\n",
        "   - Provide time/space complexity analysis\n",
        "   - Include common variations and optimizations\n",
        "   - Show pseudocode AND actual implementation\n",
        "\n",
        "8. **STRUCTURED LEARNING FLOW**: For each topic covered in this chunk:\n",
        "   - **Introduction**: What is it and why does it matter?\n",
        "   - **Intuitive Understanding**: Simple explanation with analogies\n",
        "   - **Technical Details**: Mathematical formulations, algorithms, data structures\n",
        "   - **Code Implementation**: Complete examples with explanations\n",
        "   - **Detailed Examples**: Multiple worked examples with code\n",
        "   - **Applications**: Real-world uses with specific implementations\n",
        "   - **Performance Analysis**: Complexity, trade-offs, optimizations\n",
        "   - **Common Pitfalls**: What students often get wrong (including coding mistakes)\n",
        "   - **Exam Tips**: Key points to remember for tests\n",
        "\n",
        "9. **INDUSTRY AND PRACTICAL CONTEXT**: Add relevant details about:\n",
        "   - How concepts are implemented in practice\n",
        "   - Popular libraries, frameworks, and tools\n",
        "   - Performance considerations and benchmarks\n",
        "   - Current research directions and limitations\n",
        "   - Production-level considerations\n",
        "\n",
        "10. **COMPLETION REQUIREMENT**: You must continue writing until ALL topics in the chunk are thoroughly covered. Do not stop mid-explanation or leave concepts incomplete. If approaching token limits, prioritize completing current explanations over starting new ones.\n",
        "\n",
        "**CRITICAL FORMATTING REQUIREMENTS:**\n",
        "\n",
        "11. **MATHEMATICAL EQUATIONS - MANDATORY FORMAT**: ALL mathematical equations, formulas, expressions, and symbols MUST be formatted using LaTeX block equations with double dollar signs. This is NON-NEGOTIABLE:\n",
        "    - ✅ CORRECT: Use `$$equation$$` on separate lines for ALL math\n",
        "    - ❌ NEVER use: `$equation$`, `[equation]`, or raw LaTeX without delimiters\n",
        "    - Apply this to: variables with subscripts/superscripts, fractions, summations, integrals, matrices, vectors, ALL mathematical notation which are grouped together, not for solo equations\n",
        "\n",
        "12. **RESPONSE LENGTH AND COMPLETION MANAGEMENT**:\n",
        "    - You have approximately 4000-6000 tokens available for detailed responses\n",
        "    - Plan your response to ensure completion of all topics within this limit\n",
        "    - If you have many topics to cover, provide essential details for each rather than incomplete deep-dives\n",
        "    - Always end with a complete thought, never cut off mid-sentence or mid-concept\n",
        "    - If you must choose between breadth and depth due to length constraints, prioritize covering all topics with good depth rather than leaving topics completely uncovered\n",
        "    - Monitor your response length and adjust detail level accordingly while maintaining quality\n",
        "\n",
        "13. **RESPONSE COMPLETION STRATEGIES**:\n",
        "    - Begin each topic with a brief overview to gauge required space\n",
        "    - For lengthy topics, focus on the most exam-relevant aspects first\n",
        "    - Always provide at least one complete code example per programming concept\n",
        "    - Ensure each major topic has: definition, example, and key takeaway\n",
        "    - If running short on space, summarize remaining topics with promise of coverage in subsequent chunks\n",
        "    - Never end abruptly without proper conclusion for the current topic\n",
        "\n",
        "**IMPORTANT**: This is chunk {{chunk_num}} of {len(transcript_chunks)} parts of a larger lecture. Focus only on the topics/concepts present in this specific chunk, but maintain the same detailed format and depth. You MUST complete ALL concepts mentioned in this chunk before finishing your response. Plan your response length to ensure completion while maintaining the required detail and proper LaTeX formatting for all mathematical content.\"\"\"\n",
        "\n",
        "    # Process each chunk with enhanced parameters\n",
        "    all_notes = []\n",
        "    chunk_summaries = []\n",
        "\n",
        "    for i, chunk in enumerate(transcript_chunks):\n",
        "        print(f\"🔄 Processing chunk {i+1}/{len(transcript_chunks)}... (Tokens: {count_tokens(chunk)})\")\n",
        "\n",
        "        # Create chunk-specific prompt\n",
        "        chunk_prompt = base_system_prompt.replace(\"{chunk_num}\", str(i+1))\n",
        "        full_prompt = f\"{chunk_prompt}\\n\\n**TRANSCRIPT CHUNK:**\\n{chunk}\"\n",
        "\n",
        "        # Calculate token limits with better utilization\n",
        "        input_tokens = count_tokens(full_prompt)\n",
        "        max_output = chunking_strategy['max_output_tokens_per_chunk']\n",
        "\n",
        "        # Ensure we're using close to the full limit\n",
        "        if input_tokens + max_output > 7700:  # Reduced safety buffer to use more tokens\n",
        "            max_output = max(4000, 7700 - input_tokens)  # Minimum 1000 tokens for output\n",
        "            print(f\"   Adjusted max output to: {max_output}\")\n",
        "\n",
        "        print(f\"   Input tokens: {input_tokens}, Max output: {max_output}\")\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": full_prompt,\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.2,  # Slightly lower for more consistent code generation\n",
        "                top_p=1.0,\n",
        "                model=model,\n",
        "                max_tokens=max_output\n",
        "            )\n",
        "\n",
        "            chunk_notes = response.choices[0].message.content\n",
        "            all_notes.append(f\"## Chunk {i+1} Content\\n\\n{chunk_notes}\")\n",
        "\n",
        "            # Extract a brief summary for integration\n",
        "            chunk_summaries.append(f\"Chunk {i+1}: {chunk[:200]}...\")\n",
        "\n",
        "            print(f\"✅ Chunk {i+1} completed ({count_tokens(chunk_notes)} tokens generated)\")\n",
        "\n",
        "            # Small delay to avoid rate limiting\n",
        "            time.sleep(2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing chunk {i+1}: {e}\")\n",
        "            # Add placeholder to maintain structure\n",
        "            all_notes.append(f\"## Chunk {i+1} Content\\n\\n[Error processing this chunk: {str(e)}]\")\n",
        "\n",
        "    # Create integrated final notes with enhanced integration\n",
        "    print(\"🔗 Creating integrated final notes...\")\n",
        "\n",
        "    # Combine notes for integration, but manage size intelligently\n",
        "    combined_notes = \"\\n\\n\".join(all_notes)\n",
        "    combined_tokens = count_tokens(combined_notes)\n",
        "\n",
        "    # Enhanced integration strategy\n",
        "    if combined_tokens > 7000:  # Increased threshold for better integration\n",
        "        print(\"📝 Large content detected - creating comprehensive integration...\")\n",
        "        # Create more detailed summaries of each chunk\n",
        "        summary_notes = []\n",
        "        for i, note in enumerate(all_notes):\n",
        "            # Take first 800 characters and key points\n",
        "            summary = note[:4000] + \"...\" if len(note) > 4000 else note\n",
        "            summary_notes.append(summary)\n",
        "        combined_notes = \"\\n\\n\".join(summary_notes)\n",
        "\n",
        "    # Enhanced integration prompt\n",
        "    integration_prompt = f\"\"\"Create comprehensive integrated lecture notes from the following chunk notes.\n",
        "\n",
        "**IDENTIFIED TOPICS:**\n",
        "{identified_topics}\n",
        "\n",
        "**ENHANCED INTEGRATION TASK:**\n",
        "1. Combine all chunks into coherent, comprehensive lecture notes\n",
        "2. Ensure all code examples are complete and properly formatted\n",
        "3. Remove redundancy while maintaining completeness\n",
        "4. Add connections between concepts and cross-references\n",
        "5. Include comprehensive overview and detailed summary sections\n",
        "6. For technical subjects, ensure all algorithms and implementations are complete\n",
        "7. Add a complete code examples section if applicable\n",
        "8. Create proper sections and subsections for easy navigation\n",
        "9. Ensure mathematical formulas and derivations are complete\n",
        "10. Add practical applications and real-world examples\n",
        "\n",
        "**CHUNK NOTES TO INTEGRATE:**\n",
        "{combined_notes}\n",
        "\n",
        "Create final integrated notes with proper structure, comprehensive coverage, and all code examples complete. Do not truncate or abbreviate - provide complete, exam-ready notes.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Increased token limit for integration\n",
        "        integration_tokens = count_tokens(integration_prompt)\n",
        "        max_integration_output = min(4000, 8000 - integration_tokens - 200)  # Increased integration output\n",
        "\n",
        "        final_response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": integration_prompt,\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.2,\n",
        "            model=model,\n",
        "            max_tokens=max_integration_output\n",
        "        )\n",
        "\n",
        "        final_notes = final_response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Integration failed: {e}\")\n",
        "        # Enhanced fallback: combine with better formatting\n",
        "        final_notes = f\"# Comprehensive Lecture Notes\\n\\n{chr(10).join(all_notes)}\\n\\n## Summary\\nThis document contains detailed notes covering all topics from the lecture transcript.\"\n",
        "\n",
        "    # Save all outputs with enhanced formatting\n",
        "    chunks_output_path = os.path.join(output_dir, \"individual_chunk_notes.md\")\n",
        "    with open(chunks_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"# Individual Chunk Notes\\n\\n\")\n",
        "        f.write(\"*This file contains detailed notes for each processed chunk*\\n\\n\")\n",
        "        f.write(\"\\n\\n---\\n\\n\".join(all_notes))\n",
        "\n",
        "    final_output_path = os.path.join(output_dir, \"detailed_exam_ready_notes.md\")\n",
        "    with open(final_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"# Complete Exam-Ready Lecture Notes\\n\\n\")\n",
        "        f.write(\"*Generated from lecture transcript with comprehensive coverage*\\n\\n\")\n",
        "        f.write(final_notes)\n",
        "\n",
        "    print(f\"📝 Individual chunk notes saved to: {chunks_output_path}\")\n",
        "    print(f\"📖 Final integrated notes saved to: {final_output_path}\")\n",
        "\n",
        "    # Generate enhanced study guide\n",
        "    print(\"📚 Generating comprehensive study guide...\")\n",
        "\n",
        "    # Enhanced study guide prompt\n",
        "    study_guide_prompt = f\"\"\"Based on these key topics and the comprehensive notes generated, create a detailed study guide:\n",
        "\n",
        "**KEY TOPICS:**\n",
        "{identified_topics}\n",
        "\n",
        "**ENHANCED STUDY GUIDE REQUIREMENTS:**\n",
        "- Key formulas, algorithms, and code snippets for quick reference\n",
        "- Important concepts with brief explanations\n",
        "- Code templates and common patterns\n",
        "- Quick reference format but with sufficient detail\n",
        "- Include complexity analysis for algorithms\n",
        "- Common interview questions and exam topics\n",
        "- Under 2000 words but comprehensive\n",
        "\n",
        "Focus on exam-ready and interview-ready content that students can quickly review before tests.\"\"\"\n",
        "\n",
        "    try:\n",
        "        study_guide_response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": study_guide_prompt\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.2,\n",
        "            model=model,\n",
        "            max_tokens=3000  # Increased for more comprehensive study guide\n",
        "        )\n",
        "\n",
        "        study_guide_content = study_guide_response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Study guide generation failed: {e}\")\n",
        "        study_guide_content = f\"# Comprehensive Study Guide\\n\\nBased on topics:\\n{identified_topics}\\n\\n[Study guide generation failed, but key topics are listed above]\"\n",
        "\n",
        "    # Save enhanced study guide\n",
        "    study_guide_path = os.path.join(output_dir, \"comprehensive_study_guide.md\")\n",
        "    with open(study_guide_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"# Comprehensive Study Guide\\n\\n\")\n",
        "        f.write(\"*Quick reference for exam preparation and interview practice*\\n\\n\")\n",
        "        f.write(study_guide_content)\n",
        "\n",
        "    print(f\"📋 Comprehensive study guide saved to: {study_guide_path}\")\n",
        "    print(f\"\\n🎉 Enhanced processing complete! Generated {len(transcript_chunks)} chunk notes + integrated final notes + comprehensive study guide\")\n",
        "    print(f\"📊 Token utilization: Used approximately {chunking_strategy['estimated_total_calls']} API calls with enhanced token limits\")\n",
        "\n",
        "    # Return paths for further use\n",
        "    return {\n",
        "        'individual_chunks_path': chunks_output_path,\n",
        "        'final_notes_path': final_output_path,\n",
        "        'study_guide_path': study_guide_path,\n",
        "        'chunks_processed': len(transcript_chunks),\n",
        "        'output_directory': output_dir,\n",
        "        'token_strategy': chunking_strategy\n",
        "    }\n",
        "def complete_notes_generation(transcription_result, topics_path,\n",
        "                            token=\"your_token_here\",\n",
        "                            endpoint=\"https://models.github.ai/inference\",\n",
        "                            model=\"openai/gpt-4.1\",\n",
        "                            output_dir=None):\n",
        "    \"\"\"Complete end-to-end notes generation function.\"\"\"\n",
        "    try:\n",
        "        result = generate_detailed_notes(\n",
        "            transcription_result=transcription_result,\n",
        "            topics_path=topics_path,\n",
        "            output_dir=output_dir,\n",
        "            token=token,\n",
        "            endpoint=endpoint,\n",
        "            model=model\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Notes generation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "\n",
        "# ✅ COMPLETE PIPELINE FUNCTION - FIXED VERSION\n",
        "def process_lecture_complete_pipeline(input_source,\n",
        "                                    openai_token=\"your_token_here\",\n",
        "                                    openai_endpoint=\"https://models.github.ai/inference\",\n",
        "                                    openai_model=\"openai/gpt-4.1\",\n",
        "                                    topics_model=\"meta/Llama-4-Scout-17B-16E-Instruct\",\n",
        "                                    output_dir=None,\n",
        "                                    custom_filename=None):\n",
        "    \"\"\"\n",
        "    🎯 COMPLETE LECTURE PROCESSING PIPELINE - FULLY AUTOMATED\n",
        "\n",
        "    This function handles the entire process:\n",
        "    1. Audio processing (YouTube download or local file)\n",
        "    2. Audio transcription with Whisper\n",
        "    3. Automatic topic identification from transcript\n",
        "    4. Detailed notes generation with AI\n",
        "    5. Study guide creation\n",
        "\n",
        "    Args:\n",
        "        input_source: YouTube URL or local audio/video file path\n",
        "        openai_token: Your OpenAI API token\n",
        "        openai_endpoint: API endpoint URL\n",
        "        openai_model: Model to use for notes generation\n",
        "        topics_model: Model to use for topic identification\n",
        "        output_dir: Custom output directory (optional)\n",
        "        custom_filename: Custom filename for processed audio (optional)\n",
        "\n",
        "    Returns:\n",
        "        dict: Complete results with all file paths and processing info\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🚀 STARTING COMPLETE LECTURE PROCESSING PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        # Step 1: Audio Processing & Transcription\n",
        "        print(\"📱 STEP 1: PROCESSING AUDIO & TRANSCRIPTION\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "        transcription_result = complete_transcription(\n",
        "            input_source=input_source,\n",
        "            output_filename=custom_filename,\n",
        "            save_transcript=True\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Transcription completed!\")\n",
        "        print(f\"📝 Transcript: {transcription_result['transcript_path']}\")\n",
        "        print(f\"🎵 Processed audio: {transcription_result['processed_audio_path']}\")\n",
        "\n",
        "        print(f\"😴 Sleeping for 15 seconds...\")\n",
        "        time.sleep(15)\n",
        "\n",
        "        # Step 2: Automatic Topic Identification\n",
        "        print(\"\\n🧠 STEP 2: IDENTIFYING KEY TOPICS FROM TRANSCRIPT\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "        # Generate topics file name based on transcript location\n",
        "        transcript_dir = os.path.dirname(transcription_result['transcript_path'])\n",
        "        identified_topics_path = os.path.join(transcript_dir, \"identified_topics.txt\")\n",
        "\n",
        "        identify_topics_result_path = identify_topics_from_transcript(\n",
        "            transcription_result['transcript_path'],\n",
        "            token=openai_token, # Pass the token here\n",
        "            endpoint=openai_endpoint, # Pass the endpoint here\n",
        "            model=topics_model, # Pass the topics model here\n",
        "            output_file=\"identified_topics.txt\"\n",
        "        )\n",
        "        topics_path = \"/content/processed_audio/identified_topics.txt\" # Update topics_path here\n",
        "        print(f\"✅ Topics identified and saved to: {topics_path}\")\n",
        "\n",
        "        print(f\"😴 Sleeping for 15 seconds...\")\n",
        "        time.sleep(15)\n",
        "\n",
        "        # Step 3: Notes Generation\n",
        "        print(\"\\n📚 STEP 3: GENERATING DETAILED NOTES\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "        notes_result = complete_notes_generation(\n",
        "            transcription_result=transcription_result,\n",
        "            topics_path=topics_path, # Use the potentially new topics_path\n",
        "            token=openai_token,\n",
        "            endpoint=openai_endpoint,\n",
        "            model=openai_model,\n",
        "            output_dir=output_dir\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Notes generation completed!\")\n",
        "\n",
        "        print(f\"😴 Sleeping for 15 seconds...\")\n",
        "        time.sleep(15)\n",
        "        # Step 4: Combine Results\n",
        "        final_result = {\n",
        "            # Transcription outputs\n",
        "            'transcript': transcription_result['transcript'],\n",
        "            'transcript_path': transcription_result['transcript_path'],\n",
        "            'processed_audio_path': transcription_result['processed_audio_path'],\n",
        "\n",
        "            # Notes outputs\n",
        "            'individual_chunks_path': notes_result['individual_chunks_path'],\n",
        "            'final_notes_path': notes_result['final_notes_path'],\n",
        "            'study_guide_path': notes_result['study_guide_path'],\n",
        "            'chunks_processed': notes_result['chunks_processed'],\n",
        "            'output_directory': notes_result['output_directory'],\n",
        "\n",
        "            # Pipeline info\n",
        "            'input_source': input_source,\n",
        "            'topics_used': topics_path, # Use the potentially new topics_path\n",
        "            'pipeline_success': True\n",
        "        }\n",
        "\n",
        "        # Final Summary\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🎉 PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"📁 Output Directory: {final_result['output_directory']}\")\n",
        "        print(f\"📝 Transcript: {final_result['transcript_path']}\")\n",
        "        print(f\"📖 Final Notes: {final_result['final_notes_path']}\")\n",
        "        print(f\"📋 Study Guide: {final_result['study_guide_path']}\")\n",
        "        print(f\"📊 Individual Chunks: {final_result['individual_chunks_path']}\")\n",
        "        print(f\"🎵 Processed Audio: {final_result['processed_audio_path']}\")\n",
        "        print(f\"🔢 Chunks Processed: {final_result['chunks_processed']}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return final_result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ PIPELINE FAILED: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Return error result\n",
        "        return {\n",
        "            'pipeline_success': False,\n",
        "            'error': str(e),\n",
        "            'input_source': input_source,\n",
        "            'topics_used': topics_path if 'topics_path' in locals() else None\n",
        "        }\n",
        "\n",
        "# ✅ SIMPLE USAGE FUNCTION - FIXED VERSION\n",
        "def process_lecture(youtube_url_or_file_path, your_openai_token=\"your_token_here\"):\n",
        "    \"\"\"\n",
        "    🎯 SIMPLE ONE-LINE LECTURE PROCESSOR - FULLY AUTOMATED TOPIC IDENTIFICATION\n",
        "\n",
        "    Usage:\n",
        "        result = process_lecture(\n",
        "            \"https://youtube.com/watch?v=...\",\n",
        "            \"your_openai_token\"\n",
        "        )\n",
        "    \"\"\"\n",
        "    return process_lecture_complete_pipeline(\n",
        "        input_source=youtube_url_or_file_path,\n",
        "        openai_token=your_openai_token,\n",
        "        openai_endpoint=\"https://models.github.ai/inference\",\n",
        "        openai_model=\"openai/gpt-4.1\",\n",
        "        topics_model=\"meta/Llama-4-Scout-17B-16E-Instruct\" # Default topics model\n",
        "    )\n",
        "\n",
        "# ✅ MAIN EXECUTION - FIXED VERSION\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🎓 LECTURE PROCESSING PIPELINE\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Get inputs\n",
        "    input_source = input(\"🔤 Enter YouTube URL or local file path: \").strip()\n",
        "    openai_token = input(\"🔑 Enter your OpenAI token: \").strip()\n",
        "\n",
        "    # Process lecture\n",
        "    result = process_lecture_complete_pipeline(\n",
        "        input_source=input_source,\n",
        "        openai_token=openai_token,\n",
        "        openai_endpoint=\"https://models.github.ai/inference\", # Explicitly pass endpoint\n",
        "        openai_model=\"openai/gpt-4.1\", # Explicitly pass notes model\n",
        "        topics_model=\"meta/Llama-4-Scout-17B-16E-Instruct\" # Explicitly pass topics model\n",
        "    )\n",
        "\n",
        "    if result['pipeline_success']:\n",
        "        print(\"\\n🎉 SUCCESS! All files are ready for studying.\")\n",
        "        print(f\"📚 Check your notes at: {result['final_notes_path']}\")\n",
        "    else:\n",
        "        print(f\"\\n❌ FAILED: {result['error']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHtOe3Rix3S1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIufnMod8yD5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793,
          "referenced_widgets": [
            "e1f5d53d6f0749e78526cb96024384c6",
            "868b7e55bc1b47079dbc58071bb91fcd",
            "392eaee7621d487688825deaf8d1f121",
            "2ce4e5e8da2d4243be764d0f0f99d295",
            "002e32519cf84cffaf950c5759194824",
            "b450405ac81943c49832c104556f779a",
            "5ffaf673fbc445b88129ca87fe1ba18e",
            "45299298a6f9434bb839c03da5d95655",
            "44cbcd5334684b4a8db3d9f93977638c",
            "bc4405888c0b467db93324a95fe3a211",
            "49a29f958d7e48cc96f401f06cbfa6cf",
            "562ee739674d4621a0678f257de23edb",
            "19841d3095414440a46e91d0d18ccc35",
            "484507ab375c455e9a37b18605312d24",
            "42176f7c292d493ea0515f13fb66675c",
            "acaf60752498424595fc0e280c2e49ec",
            "82b327b4744644018d6e132c5211a60c",
            "2a15f51e7798462584d217bc105b754c",
            "df273891710f42038711e7a8163de0c4",
            "d923ce5a9d6149c49bcf50c8ae25003e",
            "26fe3ccfcc3a4ff9825d8c1df77b05d3",
            "859f5944d86241e29dd8a3e569319864",
            "a426a0b6ccfa4befa3ee9c3e6417a392",
            "7a77a3b801714784983f244b6294594d",
            "a772aa9ab31f42338dd80bde272a915c",
            "5eac1cf6bfdf4979b24d5ae09135d37a",
            "f08a08d100be4524a1223ee4baff1590",
            "b702a56d22804de28c974bf894caabc2",
            "6ff8bf311b99476f9cb951c201588463",
            "58a0defa040e4143819dc9249d8fce85",
            "fa478f869e2a479ab7f5399b18ebfb4a",
            "cd36100a711a4200b4e2d9728f282d1d",
            "bf20d430a33f4ec8aae8a225b2e04425",
            "2bf1027ab5b84009884542f6b7ebf249",
            "6c8221c3e7194b969b84688481d82b0d",
            "26cd4518d98149a6868568d7708d4cb1",
            "48c14b4633654c9082a97e75ae51d4f6",
            "9a7f4a2bde4c48e2b2aa25ee10ef4a01",
            "bbdd039c8ea043d1ab0cc1bd0191a712",
            "44e4c0644b90451fbd4adc3bc95a47e7",
            "3f57ead7ce8948fb8ed5e60006b2f2d1",
            "acb40872a02b4df696e3f0df83fd4f7e",
            "09a0678b48e54ca7a2c60859fd086ce8",
            "52cb3a6d040b463d8ded91a04d4a79a0",
            "9e713b0c89f54700827437220b6b91ab",
            "982fe7ef0ea94be2954592c4d178e1e7",
            "e8ad0c278fbb4ac684c7f5a6f24ad299",
            "09c7796c616344359635354f9b624d08",
            "e9e9c0b5a72641f7b806d879257408f1",
            "9f9e01cf79da4b539c1ebe7d3e815d42",
            "eedb7cc4ab3641cd807ad8ba776f8d0b",
            "8dd87712eb3c4e24ba2dda2a82991381",
            "f43ee4ca7ce3404b9a5516170384cec1",
            "330aaeb62bcd47b29a9bd27111c25847",
            "e10465399c7d4df9b43ca13daaf6ca98",
            "715c461251234d57b1683be52f72b061",
            "1a75e298e7214bf785989f58e2600c9c",
            "85862c5988eb46e696eba0254b0e5e1c",
            "8686592343724ffeac66e9ba3e5c3971",
            "37908707d7f34262852302a7f21d3ae9",
            "6ab8919761424dbb8494bedafbc7781d",
            "cd412a23a373404e816b8d17311b7caa",
            "f2e5c1f3222144b0ab84b6cd73159337",
            "2933bcaca58b4e04bc2444590410a44b",
            "cd305642be234d4aa32be58d106ec8c0",
            "ff3c969437644cf2ab899bec8a097965",
            "fe9be3f9d8f44a989bc2ab5b39182cd1",
            "56ff07f87a3f412faa05da6f8c89d3a6",
            "84f93c0d780d4700aafe89c8f73dcdae",
            "c5b12077bc0a4c7985939eaa88c93f0c",
            "16c4b11d90e14228ae4279147931a1d1",
            "cded60cedb374190b17782da258ed83c",
            "32584446e015440ca6991ad9f8d570db",
            "3244a7baba57498b82ae3a8b41b9705a",
            "5ff8c57a47684613a4ea33670a2cc7fb",
            "340936bec9994f4c8b0c29cda3680884",
            "25f7788804f1479e9c442c44cd08d552"
          ]
        },
        "id": "RBthovpjVKXW",
        "outputId": "e5ec2620-1903-4c41-e5a5-6013a0ac45e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Detected running event loop (Jupyter/Colab), starting CLI directly...\n",
            "\n",
            "🤖 Notes RAG System - Interactive CLI\n",
            "==================================================\n",
            "🔄 Initializing RAG pipeline...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1f5d53d6f0749e78526cb96024384c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "562ee739674d4621a0678f257de23edb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a426a0b6ccfa4befa3ee9c3e6417a392",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bf1027ab5b84009884542f6b7ebf249",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e713b0c89f54700827437220b6b91ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "715c461251234d57b1683be52f72b061",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe9be3f9d8f44a989bc2ab5b39182cd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Pipeline initialized successfully!\n",
            "\n",
            "⚠️  No documents found in the database.\n",
            "You can add documents using the /ingest endpoint or by placing files in the /content/processed_audio directory\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-133696561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1025\u001b[0m                 \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                 \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m                 \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;31m# restore the current task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/events.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-133696561.py\u001b[0m in \u001b[0;36mmain_cli\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m     \u001b[0;34m\"\"\"Main CLI entry point\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0mrun_cli_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-133696561.py\u001b[0m in \u001b[0;36mrun_cli_interface\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;31m# Offer to create sample documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0mcreate_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nWould you like to create sample documents for testing? (y/n): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcreate_sample\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mawait\u001b[0m \u001b[0mcreate_sample_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# RAG Agent for Notes App - Part 2: Gemini Integration and Complete Pipeline\n",
        "# Improved version with bug fixes and better architecture\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import asyncio\n",
        "from typing import List, Dict, Any, Optional, Tuple, Union\n",
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# HTTP and API\n",
        "import aiohttp\n",
        "import requests\n",
        "from fastapi import FastAPI, HTTPException, Query, BackgroundTasks\n",
        "from pydantic import BaseModel, Field\n",
        "import uvicorn\n",
        "\n",
        "# Google Gemini\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "# Advanced retrieval\n",
        "from sentence_transformers import CrossEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# FIXED: Proper base classes that should be imported from Part 1\n",
        "# These would normally be imported, but included here for completeness\n",
        "@dataclass\n",
        "class DocumentChunk:\n",
        "    content: str\n",
        "    metadata: Dict[str, Any]\n",
        "    chunk_id: str\n",
        "    source_file: str\n",
        "    chunk_index: int\n",
        "    token_count: int\n",
        "\n",
        "class DocumentProcessor:\n",
        "    def load_markdown_file(self, file_path: str) -> str:\n",
        "        \"\"\"Load markdown file with proper error handling\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                return f.read()\n",
        "        except FileNotFoundError:\n",
        "            logger.error(f\"File not found: {file_path}\")\n",
        "            return \"\"\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading file {file_path}: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def create_chunks(self, text: str, source_file: str, file_type: str,\n",
        "                     chunk_size: int = 1000, chunk_overlap: int = 200) -> List[DocumentChunk]:\n",
        "        \"\"\"Create overlapping chunks for better context preservation\"\"\"\n",
        "        if not text.strip():\n",
        "            return []\n",
        "\n",
        "        chunks = []\n",
        "        words = text.split()\n",
        "\n",
        "        for i in range(0, len(words), chunk_size - chunk_overlap):\n",
        "            chunk_words = words[i:i + chunk_size]\n",
        "            chunk_text = ' '.join(chunk_words)\n",
        "\n",
        "            if chunk_text.strip():\n",
        "                chunk_id = f\"{Path(source_file).stem}_{i // (chunk_size - chunk_overlap)}\"\n",
        "                chunk = DocumentChunk(\n",
        "                    content=chunk_text.strip(),\n",
        "                    metadata={\n",
        "                        \"source_file\": source_file,\n",
        "                        \"file_type\": file_type,\n",
        "                        \"created_at\": datetime.now().isoformat()\n",
        "                    },\n",
        "                    chunk_id=chunk_id,\n",
        "                    source_file=source_file,\n",
        "                    chunk_index=i // (chunk_size - chunk_overlap),\n",
        "                    token_count=len(chunk_words)\n",
        "                )\n",
        "                chunks.append(chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "class VectorDatabase:\n",
        "    \"\"\"Mock vector database - replace with actual ChromaDB in production\"\"\"\n",
        "\n",
        "    def __init__(self, db_path: str = \"./chroma_db\", collection_name: str = \"notes_collection\"):\n",
        "        self.db_path = Path(db_path)\n",
        "        self.collection_name = collection_name\n",
        "        self.documents = []  # In-memory storage for demo\n",
        "        self.db_path.mkdir(exist_ok=True)\n",
        "        logger.info(f\"Initialized VectorDatabase at {db_path}\")\n",
        "\n",
        "    def add_documents(self, chunks: List[DocumentChunk]) -> None:\n",
        "        \"\"\"Add documents to the database\"\"\"\n",
        "        try:\n",
        "            for chunk in chunks:\n",
        "                # In a real implementation, you'd generate embeddings here\n",
        "                doc_dict = {\n",
        "                    'content': chunk.content,\n",
        "                    'metadata': chunk.metadata,\n",
        "                    'chunk_id': chunk.chunk_id,\n",
        "                    'similarity_score': 0.0  # Placeholder\n",
        "                }\n",
        "                self.documents.append(doc_dict)\n",
        "\n",
        "            logger.info(f\"Added {len(chunks)} documents to database\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error adding documents: {e}\")\n",
        "            raise\n",
        "\n",
        "    def search(self, query: str, n_results: int = 5,\n",
        "              file_type_filter: Optional[str] = None) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Search documents (mock implementation)\"\"\"\n",
        "        try:\n",
        "            # Filter by file type if specified\n",
        "            filtered_docs = self.documents\n",
        "            if file_type_filter:\n",
        "                filtered_docs = [\n",
        "                    doc for doc in self.documents\n",
        "                    if doc['metadata'].get('file_type') == file_type_filter\n",
        "                ]\n",
        "\n",
        "            # Mock similarity scoring based on keyword matching\n",
        "            query_words = set(query.lower().split())\n",
        "            for doc in filtered_docs:\n",
        "                content_words = set(doc['content'].lower().split())\n",
        "                similarity = len(query_words.intersection(content_words)) / max(len(query_words), 1)\n",
        "                doc['similarity_score'] = similarity\n",
        "\n",
        "            # Sort by similarity and return top results\n",
        "            sorted_docs = sorted(filtered_docs, key=lambda x: x['similarity_score'], reverse=True)\n",
        "            return sorted_docs[:n_results]\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error searching database: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_collection_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get database statistics\"\"\"\n",
        "        return {\n",
        "            \"total_chunks\": len(self.documents),\n",
        "            \"collection_name\": self.collection_name,\n",
        "            \"db_path\": str(self.db_path),\n",
        "            \"embedding_model\": \"mock_embeddings\"\n",
        "        }\n",
        "\n",
        "class NotesRAGSystem:\n",
        "    \"\"\"Enhanced RAG system with better error handling\"\"\"\n",
        "\n",
        "    def __init__(self, notes_directory: str = \"/content/processed_audio\", db_path: str = \"./chroma_db\"):\n",
        "        self.notes_directory = Path(notes_directory)\n",
        "        self.db_path = db_path\n",
        "        self.doc_processor = DocumentProcessor()\n",
        "        self.vector_db = VectorDatabase(db_path=db_path)\n",
        "\n",
        "        # FIXED: More descriptive file type mapping\n",
        "        self.file_types = {\n",
        "            \"individual\": \"main_notes\",\n",
        "            \"comprehensive\": \"study_guide\",\n",
        "            \"detailed\": \"quick_summary\",\n",
        "            \"exam\": \"quick_summary\"\n",
        "        }\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create necessary directories\"\"\"\n",
        "        try:\n",
        "            self.notes_directory.mkdir(exist_ok=True)\n",
        "            Path(self.db_path).mkdir(exist_ok=True)\n",
        "            logger.info(\"Directories setup complete\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error setting up directories: {e}\")\n",
        "            raise\n",
        "\n",
        "    def ingest_documents(self, file_paths: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"Ingest documents with detailed feedback\"\"\"\n",
        "        results = {\n",
        "            \"successful\": 0,\n",
        "            \"failed\": 0,\n",
        "            \"total_chunks\": 0,\n",
        "            \"errors\": []\n",
        "        }\n",
        "\n",
        "        all_chunks = []\n",
        "\n",
        "        for file_path in file_paths:\n",
        "            try:\n",
        "                content = self.doc_processor.load_markdown_file(file_path)\n",
        "                if not content:\n",
        "                    results[\"failed\"] += 1\n",
        "                    results[\"errors\"].append(f\"Empty or missing file: {file_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Determine file type\n",
        "                file_name = Path(file_path).stem.lower()\n",
        "                file_type = \"unknown\"\n",
        "                for key, value in self.file_types.items():\n",
        "                    if key in file_name:\n",
        "                        file_type = value\n",
        "                        break\n",
        "\n",
        "                chunks = self.doc_processor.create_chunks(content, file_path, file_type)\n",
        "                all_chunks.extend(chunks)\n",
        "                results[\"successful\"] += 1\n",
        "                results[\"total_chunks\"] += len(chunks)\n",
        "\n",
        "                logger.info(f\"Processed {file_path}: {len(chunks)} chunks\")\n",
        "\n",
        "            except Exception as e:\n",
        "                results[\"failed\"] += 1\n",
        "                results[\"errors\"].append(f\"Error processing {file_path}: {str(e)}\")\n",
        "                logger.error(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "        # Add all chunks to database\n",
        "        if all_chunks:\n",
        "            try:\n",
        "                self.vector_db.add_documents(all_chunks)\n",
        "            except Exception as e:\n",
        "                results[\"errors\"].append(f\"Database error: {str(e)}\")\n",
        "                logger.error(f\"Database ingestion error: {e}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def search_notes(self, query: str, n_results: int = 5,\n",
        "                    file_type: Optional[str] = None) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Search notes with validation\"\"\"\n",
        "        if not query.strip():\n",
        "            logger.warning(\"Empty query provided\")\n",
        "            return []\n",
        "\n",
        "        return self.vector_db.search(query, n_results, file_type)\n",
        "\n",
        "    def get_system_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get comprehensive system statistics\"\"\"\n",
        "        stats = self.vector_db.get_collection_stats()\n",
        "        stats.update({\n",
        "            \"notes_directory\": str(self.notes_directory),\n",
        "            \"supported_file_types\": list(self.file_types.values()),\n",
        "            \"file_type_mapping\": self.file_types\n",
        "        })\n",
        "        return stats\n",
        "\n",
        "@dataclass\n",
        "class RAGResponse:\n",
        "    \"\"\"Structured RAG response with validation\"\"\"\n",
        "    answer: str\n",
        "    sources: List[Dict[str, Any]]\n",
        "    confidence_score: float\n",
        "    query: str\n",
        "    response_time: float\n",
        "    metadata: Dict[str, Any]\n",
        "\n",
        "class GeminiConfig:\n",
        "    \"\"\"Configuration for Gemini API with validation\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model: str = \"gemini-1.5-flash-latest\"):\n",
        "        if not api_key:\n",
        "            raise ValueError(\"API key is required\")\n",
        "\n",
        "        self.api_key = api_key\n",
        "        self.model = model\n",
        "        self.temperature = 0.3\n",
        "        self.max_output_tokens = 2048\n",
        "        self.top_p = 0.8\n",
        "        self.top_k = 40\n",
        "\n",
        "class AdvancedRetriever:\n",
        "    \"\"\"Enhanced retrieval with better error handling\"\"\"\n",
        "\n",
        "    def __init__(self, cross_encoder_model: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"):\n",
        "        self.has_reranker = False\n",
        "        try:\n",
        "            self.cross_encoder = CrossEncoder(cross_encoder_model)\n",
        "            self.has_reranker = True\n",
        "            logger.info(f\"Loaded cross-encoder: {cross_encoder_model}\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not load cross-encoder: {e}. Using basic retrieval.\")\n",
        "\n",
        "    def expand_query(self, query: str) -> List[str]:\n",
        "        \"\"\"Generate query variations for better retrieval\"\"\"\n",
        "        if not query.strip():\n",
        "            return [query]\n",
        "\n",
        "        expansions = [query]\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        # Add common academic variations\n",
        "        if \"how\" in query_lower:\n",
        "            expansions.append(query.replace(\"how to\", \"method for\"))\n",
        "            expansions.append(query.replace(\"how\", \"what is the process of\"))\n",
        "\n",
        "        if \"what\" in query_lower:\n",
        "            expansions.append(query.replace(\"what is\", \"definition of\"))\n",
        "            expansions.append(query.replace(\"what\", \"explain\"))\n",
        "\n",
        "        # Add context-specific terms\n",
        "        academic_terms = [\"study\", \"learn\", \"understand\", \"concept\", \"method\", \"approach\"]\n",
        "        for term in academic_terms:\n",
        "            if term not in query_lower and len(expansions) < 4:\n",
        "                expansions.append(f\"{query} {term}\")\n",
        "\n",
        "        return expansions[:3]  # Limit to avoid too many queries\n",
        "\n",
        "    def rerank_results(self, query: str, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Rerank results using cross-encoder with error handling\"\"\"\n",
        "        if not self.has_reranker or len(results) <= 1:\n",
        "            return results\n",
        "\n",
        "        try:\n",
        "            # Prepare pairs for reranking\n",
        "            pairs = [(query, result['content'][:512]) for result in results]  # Limit content length\n",
        "\n",
        "            # Get reranking scores\n",
        "            scores = self.cross_encoder.predict(pairs)\n",
        "\n",
        "            # Add rerank scores to results\n",
        "            for i, result in enumerate(results):\n",
        "                result['rerank_score'] = float(scores[i])\n",
        "\n",
        "            # Sort by rerank score\n",
        "            reranked = sorted(results, key=lambda x: x.get('rerank_score', 0), reverse=True)\n",
        "\n",
        "            logger.info(f\"Reranked {len(results)} results\")\n",
        "            return reranked\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Reranking failed: {e}\")\n",
        "            return results\n",
        "\n",
        "    def filter_results_by_relevance(self, results: List[Dict[str, Any]],\n",
        "                                  min_similarity: float = 0.1) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Filter out low-relevance results\"\"\"\n",
        "        filtered = [r for r in results if r.get('similarity_score', 0) >= min_similarity]\n",
        "        logger.info(f\"Filtered {len(results)} -> {len(filtered)} results (min_sim: {min_similarity})\")\n",
        "        return filtered\n",
        "\n",
        "class GeminiRAGGenerator:\n",
        "    \"\"\"Handles response generation using Gemini with better error handling\"\"\"\n",
        "\n",
        "    def __init__(self, config: GeminiConfig):\n",
        "        self.config = config\n",
        "\n",
        "        try:\n",
        "            # Configure Gemini\n",
        "            genai.configure(api_key=config.api_key)\n",
        "\n",
        "            # Initialize model\n",
        "            self.model = genai.GenerativeModel(\n",
        "                model_name=config.model,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    temperature=config.temperature,\n",
        "                    max_output_tokens=config.max_output_tokens,\n",
        "                    top_p=config.top_p,\n",
        "                    top_k=config.top_k,\n",
        "                ),\n",
        "                safety_settings={\n",
        "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Initialized Gemini model: {config.model}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize Gemini: {e}\")\n",
        "            raise\n",
        "\n",
        "    def create_context(self, results: List[Dict[str, Any]], max_context_length: int = 4000) -> str:\n",
        "        \"\"\"Create context from retrieved documents with length control\"\"\"\n",
        "        if not results:\n",
        "            return \"No relevant context found.\"\n",
        "\n",
        "        context_parts = []\n",
        "        current_length = 0\n",
        "\n",
        "        for i, result in enumerate(results):\n",
        "            source_info = f\"[Source {i+1}: {result['metadata'].get('file_type', 'unknown')} - {Path(result['metadata'].get('source_file', 'unknown')).name}]\"\n",
        "            content = result['content']\n",
        "\n",
        "            # Estimate token count (rough approximation: 1 token ≈ 0.75 words)\n",
        "            estimated_tokens = len(content.split()) * 0.75\n",
        "\n",
        "            if current_length + estimated_tokens > max_context_length:\n",
        "                # Truncate content if needed\n",
        "                remaining_tokens = max_context_length - current_length\n",
        "                if remaining_tokens > 50:  # Only add if there's meaningful space\n",
        "                    words_to_take = int(remaining_tokens / 0.75)\n",
        "                    content = ' '.join(content.split()[:words_to_take]) + \"...\"\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            context_parts.append(f\"{source_info}\\n{content}\\n\")\n",
        "            current_length += estimated_tokens\n",
        "\n",
        "        return \"\\n---\\n\".join(context_parts)\n",
        "\n",
        "    def create_prompt(self, query: str, context: str, conversation_history: Optional[List[Dict]] = None) -> str:\n",
        "        \"\"\"Create the prompt for Gemini\"\"\"\n",
        "\n",
        "        system_prompt = \"\"\"You are an AI study assistant helping students with their notes. You have access to three types of study materials:\n",
        "\n",
        "1. **Main Notes**: Comprehensive individual study notes\n",
        "2. **Study Guide**: Guidelines on how to use the notes effectively\n",
        "3. **Quick Summary**: Condensed exam-ready notes\n",
        "\n",
        "Instructions:\n",
        "- Provide accurate, helpful answers based ONLY on the provided context\n",
        "- If the context doesn't contain enough information, say so clearly\n",
        "- Reference specific sources when possible using [Source X] notation\n",
        "- Use clear, student-friendly language\n",
        "- Structure your response with headings and bullet points when helpful\n",
        "- If asked about study methods, reference the study guide material\n",
        "- For quick reviews, prioritize the summary material\n",
        "- Do not make up information not present in the context\"\"\"\n",
        "\n",
        "        # Add conversation history if provided\n",
        "        history_text = \"\"\n",
        "        if conversation_history:\n",
        "            history_text = \"\\n\\nRecent conversation context:\\n\"\n",
        "            for turn in conversation_history[-2:]:  # Last 2 turns to avoid too much context\n",
        "                history_text += f\"Q: {turn.get('question', '')[:100]}...\\nA: {turn.get('answer', '')[:150]}...\\n\"\n",
        "\n",
        "        prompt = f\"\"\"{system_prompt}\n",
        "\n",
        "Context from your study materials:\n",
        "{context}\n",
        "{history_text}\n",
        "\n",
        "Student Question: {query}\n",
        "\n",
        "Please provide a comprehensive answer based on the context above:\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    async def generate_response(self, prompt: str) -> str:\n",
        "        \"\"\"Generate response using Gemini with timeout and error handling\"\"\"\n",
        "        try:\n",
        "            # Use asyncio.wait_for to add timeout\n",
        "            response = await asyncio.wait_for(\n",
        "                asyncio.to_thread(self.model.generate_content, prompt),\n",
        "                timeout=30.0  # 30 second timeout\n",
        "            )\n",
        "\n",
        "            if not response or not response.text:\n",
        "                raise Exception(\"Empty response from Gemini\")\n",
        "\n",
        "            return response.text\n",
        "\n",
        "        except asyncio.TimeoutError:\n",
        "            logger.error(\"Gemini API timeout\")\n",
        "            raise Exception(\"Response generation timed out\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating response: {e}\")\n",
        "            raise Exception(f\"Failed to generate response: {str(e)}\")\n",
        "\n",
        "    def calculate_confidence(self, query: str, results: List[Dict[str, Any]], response: str) -> float:\n",
        "        \"\"\"Calculate confidence score for the response\"\"\"\n",
        "        if not results or not response:\n",
        "            return 0.0\n",
        "\n",
        "        try:\n",
        "            # Factors for confidence calculation\n",
        "            avg_similarity = np.mean([r.get('similarity_score', 0) for r in results])\n",
        "            num_sources = len(results)\n",
        "            response_length = len(response.split())\n",
        "\n",
        "            # Check if response indicates uncertainty\n",
        "            uncertainty_phrases = [\"don't know\", \"not sure\", \"unclear\", \"cannot find\", \"no information\"]\n",
        "            has_uncertainty = any(phrase in response.lower() for phrase in uncertainty_phrases)\n",
        "\n",
        "            # Simple confidence calculation\n",
        "            confidence = (\n",
        "                avg_similarity * 0.4 +  # Similarity weight\n",
        "                min(num_sources / 3, 1.0) * 0.3 +  # Source diversity weight\n",
        "                min(response_length / 100, 1.0) * 0.3  # Response completeness weight\n",
        "            )\n",
        "\n",
        "            # Reduce confidence if uncertainty is detected\n",
        "            if has_uncertainty:\n",
        "                confidence *= 0.6\n",
        "\n",
        "            return min(max(confidence, 0.0), 1.0)  # Clamp between 0 and 1\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating confidence: {e}\")\n",
        "            return 0.5  # Default moderate confidence\n",
        "\n",
        "class ComprehensiveRAGPipeline:\n",
        "    \"\"\"Complete RAG pipeline with enhanced error handling and monitoring\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 gemini_api_key: str,\n",
        "                 notes_directory: str = \"/content/processed_audio\",\n",
        "                 db_path: str = \"./chroma_db\"):\n",
        "\n",
        "        # Validate inputs\n",
        "        if not gemini_api_key:\n",
        "            raise ValueError(\"Gemini API key is required\")\n",
        "\n",
        "        # Initialize components with error handling\n",
        "        try:\n",
        "            self.rag_system = NotesRAGSystem(notes_directory, db_path)\n",
        "            self.retriever = AdvancedRetriever()\n",
        "\n",
        "            # Initialize Gemini\n",
        "            gemini_config = GeminiConfig(gemini_api_key)\n",
        "            self.generator = GeminiRAGGenerator(gemini_config)\n",
        "\n",
        "            # Conversation history with size limit\n",
        "            self.conversation_history = []\n",
        "            self.max_history_size = 10\n",
        "\n",
        "            logger.info(\"Initialized Complete RAG Pipeline\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize RAG pipeline: {e}\")\n",
        "            raise\n",
        "\n",
        "    async def query(self,\n",
        "                   question: str,\n",
        "                   file_type_filter: Optional[str] = None,\n",
        "                   n_results: int = 5,\n",
        "                   use_history: bool = True) -> RAGResponse:\n",
        "        \"\"\"Complete RAG query pipeline with comprehensive error handling\"\"\"\n",
        "\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        # Validate input\n",
        "        if not question or not question.strip():\n",
        "            raise ValueError(\"Question cannot be empty\")\n",
        "\n",
        "        try:\n",
        "            # Step 1: Query expansion\n",
        "            expanded_queries = self.retriever.expand_query(question)\n",
        "            logger.info(f\"Expanded queries: {len(expanded_queries)}\")\n",
        "\n",
        "            # Step 2: Retrieve documents for each expanded query\n",
        "            all_results = []\n",
        "            for query in expanded_queries:\n",
        "                try:\n",
        "                    results = self.rag_system.search_notes(\n",
        "                        query,\n",
        "                        n_results=n_results * 2,  # Get more results for filtering\n",
        "                        file_type=file_type_filter\n",
        "                    )\n",
        "                    all_results.extend(results)\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Search failed for query '{query}': {e}\")\n",
        "\n",
        "            # Step 3: Remove duplicates by chunk_id\n",
        "            seen_ids = set()\n",
        "            unique_results = []\n",
        "            for result in all_results:\n",
        "                chunk_id = result.get('chunk_id', '')\n",
        "                if chunk_id and chunk_id not in seen_ids:\n",
        "                    unique_results.append(result)\n",
        "                    seen_ids.add(chunk_id)\n",
        "\n",
        "            logger.info(f\"Retrieved {len(unique_results)} unique results\")\n",
        "\n",
        "            # Step 4: Filter by relevance\n",
        "            filtered_results = self.retriever.filter_results_by_relevance(unique_results)\n",
        "\n",
        "            # Step 5: Rerank results\n",
        "            reranked_results = self.retriever.rerank_results(question, filtered_results)\n",
        "\n",
        "            # Take top results after reranking\n",
        "            final_results = reranked_results[:n_results]\n",
        "\n",
        "            # Step 6: Create context\n",
        "            context = self.generator.create_context(final_results)\n",
        "\n",
        "            # Step 7: Generate prompt\n",
        "            history = self.conversation_history if use_history else None\n",
        "            prompt = self.generator.create_prompt(question, context, history)\n",
        "\n",
        "            # Step 8: Generate response\n",
        "            response_text = await self.generator.generate_response(prompt)\n",
        "\n",
        "            # Step 9: Calculate confidence\n",
        "            confidence = self.generator.calculate_confidence(question, final_results, response_text)\n",
        "\n",
        "            # Step 10: Create response object\n",
        "            response_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "            rag_response = RAGResponse(\n",
        "                answer=response_text,\n",
        "                sources=[{\n",
        "                    'content': r['content'][:200] + \"...\" if len(r['content']) > 200 else r['content'],\n",
        "                    'source_file': r['metadata'].get('source_file', 'unknown'),\n",
        "                    'file_type': r['metadata'].get('file_type', 'unknown'),\n",
        "                    'similarity_score': r.get('similarity_score', 0.0),\n",
        "                    'rerank_score': r.get('rerank_score', 0.0)\n",
        "                } for r in final_results],\n",
        "                confidence_score=confidence,\n",
        "                query=question,\n",
        "                response_time=response_time,\n",
        "                metadata={\n",
        "                    'num_results_retrieved': len(unique_results),\n",
        "                    'num_results_filtered': len(filtered_results),\n",
        "                    'num_results_used': len(final_results),\n",
        "                    'context_length': len(context),\n",
        "                    'expanded_queries': expanded_queries,\n",
        "                    'has_reranker': self.retriever.has_reranker\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Step 11: Update conversation history\n",
        "            if use_history:\n",
        "                self.conversation_history.append({\n",
        "                    'question': question,\n",
        "                    'answer': response_text[:300],  # Truncated for memory efficiency\n",
        "                    'timestamp': datetime.now().isoformat(),\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "                # Keep only recent conversations\n",
        "                if len(self.conversation_history) > self.max_history_size:\n",
        "                    self.conversation_history = self.conversation_history[-self.max_history_size:]\n",
        "\n",
        "            logger.info(f\"Query completed in {response_time:.2f}s with confidence {confidence:.3f}\")\n",
        "            return rag_response\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in RAG pipeline: {e}\")\n",
        "            # Return error response instead of raising\n",
        "            response_time = (datetime.now() - start_time).total_seconds()\n",
        "            return RAGResponse(\n",
        "                answer=f\"I apologize, but I encountered an error while processing your question: {str(e)}\",\n",
        "                sources=[],\n",
        "                confidence_score=0.0,\n",
        "                query=question,\n",
        "                response_time=response_time,\n",
        "                metadata={\"error\": str(e)}\n",
        "            )\n",
        "\n",
        "    def clear_history(self):\n",
        "        \"\"\"Clear conversation history\"\"\"\n",
        "        self.conversation_history = []\n",
        "        logger.info(\"Conversation history cleared\")\n",
        "\n",
        "    def get_pipeline_status(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get pipeline status information\"\"\"\n",
        "        return {\n",
        "            \"status\": \"active\",\n",
        "            \"conversation_history_size\": len(self.conversation_history),\n",
        "            \"has_reranker\": self.retriever.has_reranker,\n",
        "            \"gemini_model\": self.generator.config.model,\n",
        "            \"system_stats\": self.rag_system.get_system_stats()\n",
        "        }\n",
        "\n",
        "# FastAPI Application with improved error handling\n",
        "app = FastAPI(\n",
        "    title=\"Notes RAG API\",\n",
        "    version=\"2.0.0\",\n",
        "    description=\"Enhanced RAG system for educational notes with Gemini integration\"\n",
        ")\n",
        "\n",
        "# Global RAG pipeline instance\n",
        "rag_pipeline: Optional[ComprehensiveRAGPipeline] = None\n",
        "\n",
        "# Enhanced utility functions and CLI interface\n",
        "\n",
        "def validate_environment():\n",
        "    \"\"\"Validate that all required dependencies are available\"\"\"\n",
        "    missing_deps = []\n",
        "\n",
        "    try:\n",
        "        import google.generativeai\n",
        "    except ImportError:\n",
        "        missing_deps.append(\"google-generativeai\")\n",
        "\n",
        "    try:\n",
        "        import sentence_transformers\n",
        "    except ImportError:\n",
        "        missing_deps.append(\"sentence-transformers\")\n",
        "\n",
        "    try:\n",
        "        import fastapi\n",
        "    except ImportError:\n",
        "        missing_deps.append(\"fastapi\")\n",
        "\n",
        "    try:\n",
        "        import uvicorn\n",
        "    except ImportError:\n",
        "        missing_deps.append(\"uvicorn\")\n",
        "\n",
        "    if missing_deps:\n",
        "        logger.error(f\"Missing dependencies: {missing_deps}\")\n",
        "        return False, missing_deps\n",
        "\n",
        "    return True, []\n",
        "\n",
        "async def run_cli_interface():\n",
        "    \"\"\"Interactive CLI interface for testing the RAG system\"\"\"\n",
        "    print(\"\\n🤖 Notes RAG System - Interactive CLI\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Check environment\n",
        "    valid_env, missing_deps = validate_environment()\n",
        "    if not valid_env:\n",
        "        print(f\"❌ Missing dependencies: {missing_deps}\")\n",
        "        print(\"Please install them with: pip install \" + \" \".join(missing_deps))\n",
        "        return\n",
        "\n",
        "    # Get API key\n",
        "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "    if not api_key:\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            api_key = userdata.get('GEMINI_API_KEY')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if not api_key:\n",
        "        print(\"❌ GEMINI_API_KEY not found!\")\n",
        "        print(\"Please set it as an environment variable or in Colab secrets.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Initialize pipeline\n",
        "        print(\"🔄 Initializing RAG pipeline...\")\n",
        "        pipeline = ComprehensiveRAGPipeline(api_key)\n",
        "        pipeline.rag_system.setup_directories()\n",
        "        print(\"✅ Pipeline initialized successfully!\")\n",
        "\n",
        "        # After this line: pipeline.rag_system.setup_directories()\n",
        "# Add this:\n",
        "        import glob\n",
        "        audio_files = glob.glob(\"/content/processed_audio/*.md\")\n",
        "        if audio_files:\n",
        "            print(f\"🔄 Found {len(audio_files)} files, ingesting...\")\n",
        "            results = pipeline.rag_system.ingest_documents(audio_files)\n",
        "            print(f\"✅ Ingested {results['successful']} files with {results['total_chunks']} chunks\")\n",
        "\n",
        "        # Check if there are any documents\n",
        "        stats = pipeline.get_pipeline_status()\n",
        "        total_docs = stats['system_stats']['total_chunks']\n",
        "\n",
        "        if total_docs == 0:\n",
        "            print(\"\\n⚠️  No documents found in the database.\")\n",
        "            print(\"You can add documents using the /ingest endpoint or by placing files in the /content/processed_audio directory\")\n",
        "\n",
        "            # Offer to create sample documents\n",
        "            create_sample = input(\"\\nWould you like to create sample documents for testing? (y/n): \").lower().strip()\n",
        "            if create_sample == 'y':\n",
        "                await create_sample_documents(pipeline)\n",
        "        else:\n",
        "            print(f\"📚 Found {total_docs} document chunks in the database\")\n",
        "\n",
        "        # Interactive query loop\n",
        "        print(\"\\n💬 You can now ask questions about your notes!\")\n",
        "        print(\"Commands:\")\n",
        "        print(\"  'quit' or 'exit' - Exit the CLI\")\n",
        "        print(\"  'stats' - Show system statistics\")\n",
        "        print(\"  'clear' - Clear conversation history\")\n",
        "        print(\"  'help' - Show this help message\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                question = input(\"\\n🤔 Your question: \").strip()\n",
        "\n",
        "                if not question:\n",
        "                    continue\n",
        "\n",
        "                if question.lower() in ['quit', 'exit']:\n",
        "                    print(\"👋 Goodbye!\")\n",
        "                    break\n",
        "\n",
        "                if question.lower() == 'stats':\n",
        "                    stats = pipeline.get_pipeline_status()\n",
        "                    print(\"\\n📊 System Statistics:\")\n",
        "                    print(f\"  - Documents: {stats['system_stats']['total_chunks']} chunks\")\n",
        "                    print(f\"  - Conversation history: {stats['conversation_history_size']} entries\")\n",
        "                    print(f\"  - Reranker available: {stats['has_reranker']}\")\n",
        "                    print(f\"  - Model: {stats['gemini_model']}\")\n",
        "                    continue\n",
        "\n",
        "                if question.lower() == 'clear':\n",
        "                    pipeline.clear_history()\n",
        "                    print(\"🗑️ Conversation history cleared!\")\n",
        "                    continue\n",
        "\n",
        "                if question.lower() == 'help':\n",
        "                    print(\"\\n💡 Help:\")\n",
        "                    print(\"Ask questions about your study notes, and I'll search through them to provide answers.\")\n",
        "                    print(\"You can ask about specific topics, request explanations, or get study guidance.\")\n",
        "                    print(\"Examples:\")\n",
        "                    print(\"  - 'What is the main concept in chapter 5?'\")\n",
        "                    print(\"  - 'How should I study for the exam?'\")\n",
        "                    print(\"  - 'Explain the difference between X and Y'\")\n",
        "                    continue\n",
        "\n",
        "                # Process the question\n",
        "                print(\"🔍 Searching and generating response...\")\n",
        "                start_time = datetime.now()\n",
        "\n",
        "                response = await pipeline.query(question)\n",
        "\n",
        "                # Display response\n",
        "                print(f\"\\n🤖 Answer (confidence: {response.confidence_score:.2f}):\")\n",
        "                print(\"-\" * 30)\n",
        "                print(response.answer)\n",
        "\n",
        "                # Show sources if available\n",
        "                if response.sources:\n",
        "                    print(f\"\\n📖 Sources ({len(response.sources)}):\")\n",
        "                    for i, source in enumerate(response.sources, 1):\n",
        "                        file_name = Path(source['source_file']).name\n",
        "                        print(f\"  {i}. {file_name} ({source['file_type']}) - Score: {source['similarity_score']:.3f}\")\n",
        "\n",
        "                print(f\"\\n⏱️ Response time: {response.response_time:.2f}s\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\n\\n👋 Interrupted by user. Goodbye!\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"\\n❌ Error: {e}\")\n",
        "                print(\"Please try again with a different question.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to initialize pipeline: {e}\")\n",
        "\n",
        "async def create_sample_documents(pipeline: ComprehensiveRAGPipeline):\n",
        "    \"\"\"Create sample documents for testing\"\"\"\n",
        "    print(\"📝 Creating sample documents...\")\n",
        "\n",
        "    # Create notes directory\n",
        "    notes_dir = Path(\"/content/processed_audio\")\n",
        "    notes_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Sample documents\n",
        "    sample_docs = {\n",
        "        \"individual_chunk_notes_physics.md\": \"\"\"# Physics Study Notes\n",
        "\n",
        "## Newton's Laws of Motion\n",
        "\n",
        "### First Law (Law of Inertia)\n",
        "An object at rest stays at rest and an object in motion stays in motion with the same speed and in the same direction unless acted upon by an unbalanced force.\n",
        "\n",
        "### Second Law\n",
        "The acceleration of an object is directly proportional to the net force acting on it and inversely proportional to its mass.\n",
        "F = ma\n",
        "\n",
        "### Third Law\n",
        "For every action, there is an equal and opposite reaction.\n",
        "\n",
        "## Energy and Work\n",
        "\n",
        "### Kinetic Energy\n",
        "KE = 1/2 * m * v²\n",
        "The energy possessed by an object due to its motion.\n",
        "\n",
        "### Potential Energy\n",
        "PE = mgh\n",
        "The energy possessed by an object due to its position.\n",
        "\n",
        "### Conservation of Energy\n",
        "Energy cannot be created or destroyed, only transformed from one form to another.\n",
        "\"\"\",\n",
        "\n",
        "        \"comprehensive_study_guide.md\": \"\"\"# Study Guide: How to Use These Physics Notes\n",
        "\n",
        "## Effective Study Strategies\n",
        "\n",
        "### 1. Active Reading\n",
        "- Don't just read passively\n",
        "- Take notes while reading\n",
        "- Ask questions about the material\n",
        "- Relate new concepts to what you already know\n",
        "\n",
        "### 2. Practice Problems\n",
        "- Work through example problems step by step\n",
        "- Try variations of problems\n",
        "- Focus on understanding the process, not memorizing solutions\n",
        "\n",
        "### 3. Concept Mapping\n",
        "- Create visual connections between related topics\n",
        "- Use diagrams to represent relationships\n",
        "- Connect mathematical formulas to physical concepts\n",
        "\n",
        "## Review Schedule\n",
        "\n",
        "### Daily Review (15 minutes)\n",
        "- Review notes from today's class\n",
        "- Identify any unclear concepts\n",
        "- Write down questions for next class\n",
        "\n",
        "### Weekly Review (1 hour)\n",
        "- Go through all notes from the week\n",
        "- Practice key formulas\n",
        "- Complete practice problems\n",
        "\n",
        "### Before Exams\n",
        "- Create summary sheets of key concepts\n",
        "- Practice old exam questions\n",
        "- Form study groups for discussion\n",
        "\"\"\",\n",
        "\n",
        "        \"detailed_exam_ready_notes.md\": \"\"\"# Physics Quick Reference - Exam Ready\n",
        "\n",
        "## Key Formulas\n",
        "\n",
        "**Newton's Second Law:** F = ma\n",
        "**Kinetic Energy:** KE = ½mv²\n",
        "**Potential Energy:** PE = mgh\n",
        "**Work:** W = Fd cos θ\n",
        "**Power:** P = W/t\n",
        "\n",
        "## Important Constants\n",
        "- g = 9.8 m/s² (acceleration due to gravity)\n",
        "- c = 3 × 10⁸ m/s (speed of light)\n",
        "\n",
        "## Problem-Solving Strategy\n",
        "1. Identify what's given and what you need to find\n",
        "2. Choose the appropriate formula\n",
        "3. Substitute values and solve\n",
        "4. Check units and reasonableness of answer\n",
        "\n",
        "## Common Mistakes to Avoid\n",
        "- Forgetting to convert units\n",
        "- Using wrong signs for vectors\n",
        "- Not considering direction in vector problems\n",
        "- Mixing up kinetic and potential energy\n",
        "\n",
        "## Exam Tips\n",
        "- Read questions carefully\n",
        "- Show all work\n",
        "- Include units in final answers\n",
        "- Double-check calculations\n",
        "\"\"\"\n",
        "    }\n",
        "\n",
        "    # Write sample files\n",
        "    created_files = []\n",
        "    for filename, content in sample_docs.items():\n",
        "        file_path = notes_dir / filename\n",
        "        try:\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            created_files.append(str(file_path))\n",
        "            print(f\"  ✅ Created: {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ Failed to create {filename}: {e}\")\n",
        "\n",
        "    # Ingest the documents\n",
        "    if created_files:\n",
        "        try:\n",
        "            print(\"🔄 Ingesting sample documents...\")\n",
        "            results = pipeline.rag_system.ingest_documents(created_files)\n",
        "            print(f\"✅ Successfully ingested {results['successful']} documents with {results['total_chunks']} chunks\")\n",
        "\n",
        "            if results['errors']:\n",
        "                print(\"⚠️ Some errors occurred:\")\n",
        "                for error in results['errors']:\n",
        "                    print(f\"  - {error}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to ingest documents: {e}\")\n",
        "\n",
        "def run_api_server(host: str = \"0.0.0.0\", port: int = 8000):\n",
        "    \"\"\"Run the FastAPI server with proper configuration\"\"\"\n",
        "    print(f\"🚀 Starting Notes RAG API server on {host}:{port}\")\n",
        "    print(\"📖 API Documentation will be available at:\")\n",
        "    print(f\"   - Swagger UI: http://{host}:{port}/docs\")\n",
        "    print(f\"   - ReDoc: http://{host}:{port}/redoc\")\n",
        "\n",
        "    try:\n",
        "        # For Jupyter/Colab environments\n",
        "        try:\n",
        "            import nest_asyncio\n",
        "            nest_asyncio.apply()\n",
        "            print(\"✅ Applied nest_asyncio patch for Jupyter/Colab\")\n",
        "        except ImportError:\n",
        "            print(\"ℹ️ nest_asyncio not available (not needed for standalone execution)\")\n",
        "\n",
        "        # Configure uvicorn\n",
        "        config = uvicorn.Config(\n",
        "            app=app,\n",
        "            host=host,\n",
        "            port=port,\n",
        "            log_level=\"info\",\n",
        "            reload=False  # Disable reload for stability\n",
        "        )\n",
        "\n",
        "        server = uvicorn.Server(config)\n",
        "        server.run()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to start server: {e}\")\n",
        "        print(\"💡 Try using a different port or check if the port is already in use\")\n",
        "\n",
        "# Main execution functions\n",
        "async def main_cli():\n",
        "    \"\"\"Main CLI entry point\"\"\"\n",
        "    await run_cli_interface()\n",
        "\n",
        "def main_api():\n",
        "    \"\"\"Main API entry point\"\"\"\n",
        "    run_api_server()\n",
        "\n",
        "# Example usage and testing\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "\n",
        "    if len(sys.argv) > 1 and sys.argv[1] == \"api\":\n",
        "        # Run API server\n",
        "        main_api()\n",
        "    else:\n",
        "        # Run CLI interface\n",
        "        try:\n",
        "            asyncio.run(main_cli())\n",
        "        except RuntimeError as e:\n",
        "            if \"asyncio.run() cannot be called from a running event loop\" in str(e):\n",
        "                print(\"🔄 Detected running event loop (Jupyter/Colab), starting CLI directly...\")\n",
        "                # For Jupyter/Colab environments\n",
        "                import nest_asyncio\n",
        "                nest_asyncio.apply()\n",
        "                loop = asyncio.get_event_loop()\n",
        "                loop.run_until_complete(main_cli())\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "# Convenience functions for Jupyter/Colab usage\n",
        "def start_api():\n",
        "    \"\"\"Convenience function to start API server in Jupyter/Colab\"\"\"\n",
        "    main_api()\n",
        "\n",
        "def start_cli():\n",
        "    \"\"\"Convenience function to start CLI in Jupyter/Colab\"\"\"\n",
        "    try:\n",
        "        asyncio.run(main_cli())\n",
        "    except RuntimeError:\n",
        "        # Handle nested event loop in Jupyter/Colab\n",
        "        import nest_asyncio\n",
        "        nest_asyncio.apply()\n",
        "        loop = asyncio.get_event_loop()\n",
        "        loop.run_until_complete(main_cli())\n",
        "\n",
        "# Quick test function\n",
        "async def quick_test():\n",
        "    \"\"\"Quick test function to verify the system works\"\"\"\n",
        "    print(\"🧪 Running quick test...\")\n",
        "\n",
        "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "    if not api_key:\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            api_key = userdata.get('GEMINI_API_KEY')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if not api_key:\n",
        "        print(\"❌ GEMINI_API_KEY not found!\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Initialize minimal pipeline\n",
        "        pipeline = ComprehensiveRAGPipeline(api_key)\n",
        "\n",
        "        # Create a test document\n",
        "        test_content = \"The capital of France is Paris. Paris is known for the Eiffel Tower.\"\n",
        "        chunks = [DocumentChunk(\n",
        "            content=test_content,\n",
        "            metadata={\"source_file\": \"test.md\", \"file_type\": \"main_notes\"},\n",
        "            chunk_id=\"test_1\",\n",
        "            source_file=\"test.md\",\n",
        "            chunk_index=0,\n",
        "            token_count=12\n",
        "        )]\n",
        "\n",
        "        pipeline.rag_system.vector_db.add_documents(chunks)\n",
        "\n",
        "        # Test query\n",
        "        response = await pipeline.query(\"What is the capital of France?\")\n",
        "\n",
        "        print(f\"✅ Test completed successfully!\")\n",
        "        print(f\"   Answer: {response.answer[:100]}...\")\n",
        "        print(f\"   Confidence: {response.confidence_score:.3f}\")\n",
        "        print(f\"   Response time: {response.response_time:.2f}s\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Usage instructions\n",
        "print(\"\"\"\n",
        "📚 Notes RAG System - Enhanced Version\n",
        "\n",
        "🚀 Quick Start:\n",
        "  1. Set your GEMINI_API_KEY environment variable\n",
        "  2. Run one of these commands:\n",
        "\n",
        "CLI Interface:\n",
        "  python script.py\n",
        "  # OR in Jupyter/Colab:\n",
        "  start_cli()\n",
        "\n",
        "API Server:\n",
        "  python script.py api\n",
        "  # OR in Jupyter/Colab:\n",
        "  start_api()\n",
        "\n",
        "Quick Test:\n",
        "  # In Jupyter/Colab:\n",
        "  await quick_test()\n",
        "\n",
        "📖 For full documentation, visit the API docs at /docs when running the server.\n",
        "\"\"\")#d Pydantic models\n",
        "class QueryRequest(BaseModel):\n",
        "    question: str = Field(..., min_length=1, max_length=1000, description=\"The question to ask\")\n",
        "    file_type_filter: Optional[str] = Field(None, description=\"Filter by file type: main_notes, study_guide, or quick_summary\")\n",
        "    n_results: int = Field(5, ge=1, le=20, description=\"Number of results to retrieve\")\n",
        "    use_history: bool = Field(True, description=\"Whether to use conversation history\")\n",
        "\n",
        "class QueryResponse(BaseModel):\n",
        "    answer: str\n",
        "    sources: List[Dict[str, Any]]\n",
        "    confidence_score: float\n",
        "    query: str\n",
        "    response_time: float\n",
        "    metadata: Dict[str, Any]\n",
        "\n",
        "class IngestRequest(BaseModel):\n",
        "    file_paths: List[str] = Field(..., min_items=1, description=\"List of file paths to ingest\")\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    \"\"\"Initialize RAG pipeline on startup with better error handling\"\"\"\n",
        "    global rag_pipeline\n",
        "\n",
        "    try:\n",
        "        # Get API key from environment with multiple fallback options\n",
        "        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "        if not gemini_api_key:\n",
        "            # Try Colab userdata\n",
        "            try:\n",
        "                from google.colab import userdata\n",
        "                gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
        "            except (ImportError, Exception):\n",
        "                pass\n",
        "\n",
        "        if not gemini_api_key:\n",
        "            logger.error(\"GEMINI_API_KEY not found in environment variables or Colab secrets\")\n",
        "            raise Exception(\"GEMINI_API_KEY is required. Please set it as an environment variable.\")\n",
        "\n",
        "        # Initialize pipeline\n",
        "        rag_pipeline = ComprehensiveRAGPipeline(gemini_api_key)\n",
        "\n",
        "        # Setup directories\n",
        "        rag_pipeline.rag_system.setup_directories()\n",
        "\n",
        "        logger.info(\"RAG API startup complete\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Startup failed: {e}\")\n",
        "        raise\n",
        "\n",
        "@app.post(\"/query\", response_model=QueryResponse)\n",
        "async def query_notes(request: QueryRequest):\n",
        "    \"\"\"Query the notes RAG system\"\"\"\n",
        "    if not rag_pipeline:\n",
        "        raise HTTPException(status_code=503, detail=\"RAG pipeline not initialized\")\n",
        "\n",
        "    try:\n",
        "        response = await rag_pipeline.query(\n",
        "            question=request.question,\n",
        "            file_type_filter=request.file_type_filter,\n",
        "            n_results=request.n_results,\n",
        "            use_history=request.use_history\n",
        "        )\n",
        "\n",
        "        return QueryResponse(**asdict(response))\n",
        "\n",
        "    except ValueError as e:\n",
        "        raise HTTPException(status_code=400, detail=str(e))\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Query failed: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=\"Internal server error occurred\")\n",
        "\n",
        "@app.post(\"/ingest\")\n",
        "async def ingest_documents(request: IngestRequest, background_tasks: BackgroundTasks):\n",
        "    \"\"\"Ingest documents into the RAG system\"\"\"\n",
        "    if not rag_pipeline:\n",
        "        raise HTTPException(status_code=503, detail=\"RAG pipeline not initialized\")\n",
        "\n",
        "    try:\n",
        "        # Validate file paths\n",
        "        for file_path in request.file_paths:\n",
        "            if not Path(file_path).exists():\n",
        "                raise HTTPException(status_code=400, detail=f\"File not found: {file_path}\")\n",
        "\n",
        "        # Process ingestion\n",
        "        results = rag_pipeline.rag_system.ingest_documents(request.file_paths)\n",
        "\n",
        "        return {\n",
        "            \"message\": f\"Ingestion completed\",\n",
        "            \"results\": results\n",
        "        }\n",
        "\n",
        "    except HTTPException:\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ingestion failed: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=\"Ingestion failed\")\n",
        "\n",
        "@app.get(\"/stats\")\n",
        "async def get_stats():\n",
        "    \"\"\"Get comprehensive system statistics\"\"\"\n",
        "    if not rag_pipeline:\n",
        "        raise HTTPException(status_code=503, detail=\"RAG pipeline not initialized\")\n",
        "\n",
        "    try:\n",
        "        return rag_pipeline.get_pipeline_status()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Stats retrieval failed: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=\"Could not retrieve stats\")\n",
        "\n",
        "@app.delete(\"/history\")\n",
        "async def clear_conversation_history():\n",
        "    \"\"\"Clear conversation history\"\"\"\n",
        "    if not rag_pipeline:\n",
        "        raise HTTPException(status_code=503, detail=\"RAG pipeline not initialized\")\n",
        "\n",
        "    try:\n",
        "        rag_pipeline.clear_history()\n",
        "        return {\"message\": \"Conversation history cleared successfully\"}\n",
        "    except Exception as e:\n",
        "        logger.error(f\"History clearing failed: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=\"Could not clear history\")\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return {\n",
        "        \"status\": \"healthy\" if rag_pipeline else \"unhealthy\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"version\": \"2.0.0\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tys2U2bcVT_O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCuKNv4FBIs-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKHlXVheCzLG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwGqavCrQYdw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gec-mhKB6eUj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Dws4hyi68Rq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVb6yHVW91cD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWgXSowE_CUp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNGiEo6p_apt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prUsutK1_FvS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyuc3j0dSjve"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBvX02guStUW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwWyXkeeTVeu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1L9ibGHUDJz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJGDXy4SUH8p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyWj2waoVQuH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5X-l1p5XOca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s84AC3kQZPHk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE_R4D75Sdgf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej4cQ7MrUi5n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002e32519cf84cffaf950c5759194824": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a0678b48e54ca7a2c60859fd086ce8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c7796c616344359635354f9b624d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_330aaeb62bcd47b29a9bd27111c25847",
            "placeholder": "​",
            "style": "IPY_MODEL_e10465399c7d4df9b43ca13daaf6ca98",
            "value": " 711k/? [00:00&lt;00:00, 8.06MB/s]"
          }
        },
        "16c4b11d90e14228ae4279147931a1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19841d3095414440a46e91d0d18ccc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b327b4744644018d6e132c5211a60c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a15f51e7798462584d217bc105b754c",
            "value": "model.safetensors: 100%"
          }
        },
        "1a75e298e7214bf785989f58e2600c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ab8919761424dbb8494bedafbc7781d",
            "placeholder": "​",
            "style": "IPY_MODEL_cd412a23a373404e816b8d17311b7caa",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "25f7788804f1479e9c442c44cd08d552": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26cd4518d98149a6868568d7708d4cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f57ead7ce8948fb8ed5e60006b2f2d1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acb40872a02b4df696e3f0df83fd4f7e",
            "value": 1
          }
        },
        "26fe3ccfcc3a4ff9825d8c1df77b05d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2933bcaca58b4e04bc2444590410a44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a15f51e7798462584d217bc105b754c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bf1027ab5b84009884542f6b7ebf249": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c8221c3e7194b969b84688481d82b0d",
              "IPY_MODEL_26cd4518d98149a6868568d7708d4cb1",
              "IPY_MODEL_48c14b4633654c9082a97e75ae51d4f6"
            ],
            "layout": "IPY_MODEL_9a7f4a2bde4c48e2b2aa25ee10ef4a01"
          }
        },
        "2ce4e5e8da2d4243be764d0f0f99d295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc4405888c0b467db93324a95fe3a211",
            "placeholder": "​",
            "style": "IPY_MODEL_49a29f958d7e48cc96f401f06cbfa6cf",
            "value": " 794/794 [00:00&lt;00:00, 13.4kB/s]"
          }
        },
        "3244a7baba57498b82ae3a8b41b9705a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "32584446e015440ca6991ad9f8d570db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "330aaeb62bcd47b29a9bd27111c25847": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "340936bec9994f4c8b0c29cda3680884": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37908707d7f34262852302a7f21d3ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "392eaee7621d487688825deaf8d1f121": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45299298a6f9434bb839c03da5d95655",
            "max": 794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44cbcd5334684b4a8db3d9f93977638c",
            "value": 794
          }
        },
        "3f57ead7ce8948fb8ed5e60006b2f2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "42176f7c292d493ea0515f13fb66675c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26fe3ccfcc3a4ff9825d8c1df77b05d3",
            "placeholder": "​",
            "style": "IPY_MODEL_859f5944d86241e29dd8a3e569319864",
            "value": " 90.9M/90.9M [00:02&lt;00:00, 35.5MB/s]"
          }
        },
        "44cbcd5334684b4a8db3d9f93977638c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44e4c0644b90451fbd4adc3bc95a47e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45299298a6f9434bb839c03da5d95655": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484507ab375c455e9a37b18605312d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df273891710f42038711e7a8163de0c4",
            "max": 90870598,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d923ce5a9d6149c49bcf50c8ae25003e",
            "value": 90870598
          }
        },
        "48c14b4633654c9082a97e75ae51d4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a0678b48e54ca7a2c60859fd086ce8",
            "placeholder": "​",
            "style": "IPY_MODEL_52cb3a6d040b463d8ded91a04d4a79a0",
            "value": " 232k/? [00:00&lt;00:00, 3.82MB/s]"
          }
        },
        "49a29f958d7e48cc96f401f06cbfa6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52cb3a6d040b463d8ded91a04d4a79a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "562ee739674d4621a0678f257de23edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19841d3095414440a46e91d0d18ccc35",
              "IPY_MODEL_484507ab375c455e9a37b18605312d24",
              "IPY_MODEL_42176f7c292d493ea0515f13fb66675c"
            ],
            "layout": "IPY_MODEL_acaf60752498424595fc0e280c2e49ec"
          }
        },
        "56ff07f87a3f412faa05da6f8c89d3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cded60cedb374190b17782da258ed83c",
            "placeholder": "​",
            "style": "IPY_MODEL_32584446e015440ca6991ad9f8d570db",
            "value": "README.md: "
          }
        },
        "58a0defa040e4143819dc9249d8fce85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5eac1cf6bfdf4979b24d5ae09135d37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd36100a711a4200b4e2d9728f282d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_bf20d430a33f4ec8aae8a225b2e04425",
            "value": " 1.33k/? [00:00&lt;00:00, 31.1kB/s]"
          }
        },
        "5ff8c57a47684613a4ea33670a2cc7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ffaf673fbc445b88129ca87fe1ba18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ab8919761424dbb8494bedafbc7781d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8221c3e7194b969b84688481d82b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbdd039c8ea043d1ab0cc1bd0191a712",
            "placeholder": "​",
            "style": "IPY_MODEL_44e4c0644b90451fbd4adc3bc95a47e7",
            "value": "vocab.txt: "
          }
        },
        "6ff8bf311b99476f9cb951c201588463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "715c461251234d57b1683be52f72b061": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a75e298e7214bf785989f58e2600c9c",
              "IPY_MODEL_85862c5988eb46e696eba0254b0e5e1c",
              "IPY_MODEL_8686592343724ffeac66e9ba3e5c3971"
            ],
            "layout": "IPY_MODEL_37908707d7f34262852302a7f21d3ae9"
          }
        },
        "7a77a3b801714784983f244b6294594d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b702a56d22804de28c974bf894caabc2",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff8bf311b99476f9cb951c201588463",
            "value": "tokenizer_config.json: "
          }
        },
        "82b327b4744644018d6e132c5211a60c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f93c0d780d4700aafe89c8f73dcdae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3244a7baba57498b82ae3a8b41b9705a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ff8c57a47684613a4ea33670a2cc7fb",
            "value": 1
          }
        },
        "85862c5988eb46e696eba0254b0e5e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2e5c1f3222144b0ab84b6cd73159337",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2933bcaca58b4e04bc2444590410a44b",
            "value": 132
          }
        },
        "859f5944d86241e29dd8a3e569319864": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8686592343724ffeac66e9ba3e5c3971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd305642be234d4aa32be58d106ec8c0",
            "placeholder": "​",
            "style": "IPY_MODEL_ff3c969437644cf2ab899bec8a097965",
            "value": " 132/132 [00:00&lt;00:00, 2.37kB/s]"
          }
        },
        "868b7e55bc1b47079dbc58071bb91fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b450405ac81943c49832c104556f779a",
            "placeholder": "​",
            "style": "IPY_MODEL_5ffaf673fbc445b88129ca87fe1ba18e",
            "value": "config.json: 100%"
          }
        },
        "8dd87712eb3c4e24ba2dda2a82991381": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "982fe7ef0ea94be2954592c4d178e1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9e01cf79da4b539c1ebe7d3e815d42",
            "placeholder": "​",
            "style": "IPY_MODEL_eedb7cc4ab3641cd807ad8ba776f8d0b",
            "value": "tokenizer.json: "
          }
        },
        "9a7f4a2bde4c48e2b2aa25ee10ef4a01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e713b0c89f54700827437220b6b91ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_982fe7ef0ea94be2954592c4d178e1e7",
              "IPY_MODEL_e8ad0c278fbb4ac684c7f5a6f24ad299",
              "IPY_MODEL_09c7796c616344359635354f9b624d08"
            ],
            "layout": "IPY_MODEL_e9e9c0b5a72641f7b806d879257408f1"
          }
        },
        "9f9e01cf79da4b539c1ebe7d3e815d42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a426a0b6ccfa4befa3ee9c3e6417a392": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a77a3b801714784983f244b6294594d",
              "IPY_MODEL_a772aa9ab31f42338dd80bde272a915c",
              "IPY_MODEL_5eac1cf6bfdf4979b24d5ae09135d37a"
            ],
            "layout": "IPY_MODEL_f08a08d100be4524a1223ee4baff1590"
          }
        },
        "a772aa9ab31f42338dd80bde272a915c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a0defa040e4143819dc9249d8fce85",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa478f869e2a479ab7f5399b18ebfb4a",
            "value": 1
          }
        },
        "acaf60752498424595fc0e280c2e49ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb40872a02b4df696e3f0df83fd4f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b450405ac81943c49832c104556f779a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b702a56d22804de28c974bf894caabc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbdd039c8ea043d1ab0cc1bd0191a712": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc4405888c0b467db93324a95fe3a211": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf20d430a33f4ec8aae8a225b2e04425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5b12077bc0a4c7985939eaa88c93f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_340936bec9994f4c8b0c29cda3680884",
            "placeholder": "​",
            "style": "IPY_MODEL_25f7788804f1479e9c442c44cd08d552",
            "value": " 3.66k/? [00:00&lt;00:00, 124kB/s]"
          }
        },
        "cd305642be234d4aa32be58d106ec8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd36100a711a4200b4e2d9728f282d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd412a23a373404e816b8d17311b7caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cded60cedb374190b17782da258ed83c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d923ce5a9d6149c49bcf50c8ae25003e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df273891710f42038711e7a8163de0c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e10465399c7d4df9b43ca13daaf6ca98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1f5d53d6f0749e78526cb96024384c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_868b7e55bc1b47079dbc58071bb91fcd",
              "IPY_MODEL_392eaee7621d487688825deaf8d1f121",
              "IPY_MODEL_2ce4e5e8da2d4243be764d0f0f99d295"
            ],
            "layout": "IPY_MODEL_002e32519cf84cffaf950c5759194824"
          }
        },
        "e8ad0c278fbb4ac684c7f5a6f24ad299": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd87712eb3c4e24ba2dda2a82991381",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f43ee4ca7ce3404b9a5516170384cec1",
            "value": 1
          }
        },
        "e9e9c0b5a72641f7b806d879257408f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eedb7cc4ab3641cd807ad8ba776f8d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f08a08d100be4524a1223ee4baff1590": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e5c1f3222144b0ab84b6cd73159337": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43ee4ca7ce3404b9a5516170384cec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa478f869e2a479ab7f5399b18ebfb4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe9be3f9d8f44a989bc2ab5b39182cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56ff07f87a3f412faa05da6f8c89d3a6",
              "IPY_MODEL_84f93c0d780d4700aafe89c8f73dcdae",
              "IPY_MODEL_c5b12077bc0a4c7985939eaa88c93f0c"
            ],
            "layout": "IPY_MODEL_16c4b11d90e14228ae4279147931a1d1"
          }
        },
        "ff3c969437644cf2ab899bec8a097965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ae73cc09933497b81a35f77359fa5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e3da4a954574e92994b2491e7ed3a06",
              "IPY_MODEL_74cba72fb72a43e191f0a22c0a5c0243",
              "IPY_MODEL_c0a65e63a9ce4d219c9b4527f6437ba0"
            ],
            "layout": "IPY_MODEL_b5c455920a344961a04e42324ace049c"
          }
        },
        "2e3da4a954574e92994b2491e7ed3a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81666028411d4ddd985feed0f396f524",
            "placeholder": "​",
            "style": "IPY_MODEL_ff09004f58b24292a8d71a28f0c36853",
            "value": "config.json: "
          }
        },
        "74cba72fb72a43e191f0a22c0a5c0243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3fe74b3d03a4309b1976e2e4d13d572",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef1e1a811ad0488a8578300c1d3bd95c",
            "value": 1
          }
        },
        "c0a65e63a9ce4d219c9b4527f6437ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d123ba583099474eb33380d61919726e",
            "placeholder": "​",
            "style": "IPY_MODEL_4e1a3ec22bc24536bb726504c85adcc7",
            "value": " 1.97k/? [00:00&lt;00:00, 102kB/s]"
          }
        },
        "b5c455920a344961a04e42324ace049c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81666028411d4ddd985feed0f396f524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff09004f58b24292a8d71a28f0c36853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3fe74b3d03a4309b1976e2e4d13d572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ef1e1a811ad0488a8578300c1d3bd95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d123ba583099474eb33380d61919726e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1a3ec22bc24536bb726504c85adcc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3501fe42ce248b89b34626a7ca05755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ce7182f91c540bda7043879ef277319",
              "IPY_MODEL_2d58958f3a5f4f2dadfcdde69c75fe29",
              "IPY_MODEL_5ac46c5c593741cd9548f205e71476b4"
            ],
            "layout": "IPY_MODEL_183778350de94bacb647051143f2298b"
          }
        },
        "0ce7182f91c540bda7043879ef277319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa06b2508a5e411aa74490ce2163f03e",
            "placeholder": "​",
            "style": "IPY_MODEL_5c8cdee9154344fab2c3860d38f29e08",
            "value": "model.safetensors: 100%"
          }
        },
        "2d58958f3a5f4f2dadfcdde69c75fe29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2c36a31e13419a9c0785fa5d845f4c",
            "max": 966995080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb4fd6d6108046f18c358c4f33e123bb",
            "value": 966995080
          }
        },
        "5ac46c5c593741cd9548f205e71476b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9ba03a594c4c189e80ece1cb7d9ee2",
            "placeholder": "​",
            "style": "IPY_MODEL_84b4eb739fd44177a167a95518c87f3d",
            "value": " 967M/967M [00:20&lt;00:00, 61.5MB/s]"
          }
        },
        "183778350de94bacb647051143f2298b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa06b2508a5e411aa74490ce2163f03e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c8cdee9154344fab2c3860d38f29e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe2c36a31e13419a9c0785fa5d845f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb4fd6d6108046f18c358c4f33e123bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c9ba03a594c4c189e80ece1cb7d9ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84b4eb739fd44177a167a95518c87f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f011ab6fdb04ae09febd0116f87749e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_517c06e6945b44859e619e2d86a26705",
              "IPY_MODEL_40323f6339f64da18820a698f3452332",
              "IPY_MODEL_4bca5ad5f58548469cce90bd26ea9ee7"
            ],
            "layout": "IPY_MODEL_96583d01ffee491db9d80c0f685e0422"
          }
        },
        "517c06e6945b44859e619e2d86a26705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1002a65dbf949dd9f547b7b9c9a7a7d",
            "placeholder": "​",
            "style": "IPY_MODEL_d31246fa30754c9da7764c1bd1a30fde",
            "value": "generation_config.json: "
          }
        },
        "40323f6339f64da18820a698f3452332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db8cc13a47146279d40bba80565cf14",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cdf0d40e0ed40c7b8b87c1671c73212",
            "value": 1
          }
        },
        "4bca5ad5f58548469cce90bd26ea9ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087694d3be974e3ca43eeafb16168747",
            "placeholder": "​",
            "style": "IPY_MODEL_660b5d480b554dfb9d388c7d260313aa",
            "value": " 3.87k/? [00:00&lt;00:00, 174kB/s]"
          }
        },
        "96583d01ffee491db9d80c0f685e0422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1002a65dbf949dd9f547b7b9c9a7a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31246fa30754c9da7764c1bd1a30fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1db8cc13a47146279d40bba80565cf14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0cdf0d40e0ed40c7b8b87c1671c73212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "087694d3be974e3ca43eeafb16168747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660b5d480b554dfb9d388c7d260313aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f71bd4dc9ad84a7eb8e52b858c57e01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c81f437b8dba446ca721f6874fc4a8c0",
              "IPY_MODEL_4ed40cc3465d4a71b5b8ce740e384bc0",
              "IPY_MODEL_81fcdd14a9ff4c71bba4dc591ff980e2"
            ],
            "layout": "IPY_MODEL_6f3d37ec903847e1a5680acdc4a58e00"
          }
        },
        "c81f437b8dba446ca721f6874fc4a8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eaa559453c249e3990374c831e102ad",
            "placeholder": "​",
            "style": "IPY_MODEL_a120567118af4d789bea078d2f537c08",
            "value": "tokenizer_config.json: "
          }
        },
        "4ed40cc3465d4a71b5b8ce740e384bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23bce9a851c44a519d1130a76895341c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a087909e9d9f49d9a6f072e9444c0fa9",
            "value": 1
          }
        },
        "81fcdd14a9ff4c71bba4dc591ff980e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af0a84d8d8a4feba26ec54fe9173f28",
            "placeholder": "​",
            "style": "IPY_MODEL_19e15d5610dc450ebc8dfd3ecf85f206",
            "value": " 283k/? [00:00&lt;00:00, 19.5MB/s]"
          }
        },
        "6f3d37ec903847e1a5680acdc4a58e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eaa559453c249e3990374c831e102ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a120567118af4d789bea078d2f537c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23bce9a851c44a519d1130a76895341c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a087909e9d9f49d9a6f072e9444c0fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5af0a84d8d8a4feba26ec54fe9173f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e15d5610dc450ebc8dfd3ecf85f206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c682df8c95844d2eb257bf8085568bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96f56962f5c3448c8297abf594b308fa",
              "IPY_MODEL_cc4f2ca92eab4c78992f802da65e07cc",
              "IPY_MODEL_d44037f8d3674c87901d3c363eb27324"
            ],
            "layout": "IPY_MODEL_7817160754bd47f6b1647763ea5e3eb1"
          }
        },
        "96f56962f5c3448c8297abf594b308fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3df6f014107b4c0db134c3fdec4988b9",
            "placeholder": "​",
            "style": "IPY_MODEL_464e756d47b241eeae334340bbae00c0",
            "value": "vocab.json: "
          }
        },
        "cc4f2ca92eab4c78992f802da65e07cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2585e7021c146f69bc56ed3cd166075",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2eb7998185d940e58812f956f516efcf",
            "value": 1
          }
        },
        "d44037f8d3674c87901d3c363eb27324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eef219a470f4cd2869932cbb76e6706",
            "placeholder": "​",
            "style": "IPY_MODEL_a76f066a2a8f4e85b16a06baa75b71b7",
            "value": " 836k/? [00:00&lt;00:00, 8.85MB/s]"
          }
        },
        "7817160754bd47f6b1647763ea5e3eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df6f014107b4c0db134c3fdec4988b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464e756d47b241eeae334340bbae00c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2585e7021c146f69bc56ed3cd166075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2eb7998185d940e58812f956f516efcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9eef219a470f4cd2869932cbb76e6706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a76f066a2a8f4e85b16a06baa75b71b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62324d86dee845a9bba2a57e624a1e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c5a22b88af9410196f65be091eeb873",
              "IPY_MODEL_c0b25c3234f2407ab8fb22ffcc6fd369",
              "IPY_MODEL_38f1d0bc95b748ee8d04d0a78215c9d1"
            ],
            "layout": "IPY_MODEL_8d6c5706876b45a0ba12d99199fb6c8f"
          }
        },
        "0c5a22b88af9410196f65be091eeb873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c94d194b9db4d58b28af6aaf82e2ee6",
            "placeholder": "​",
            "style": "IPY_MODEL_a615484154c04082bff5f65005ba1816",
            "value": "tokenizer.json: "
          }
        },
        "c0b25c3234f2407ab8fb22ffcc6fd369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acd854b100fe499a9567836ffb50e48a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5812276ed8b24059a4ec769125dc86a5",
            "value": 1
          }
        },
        "38f1d0bc95b748ee8d04d0a78215c9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d6654f71c2a4b139d2e3f792e493677",
            "placeholder": "​",
            "style": "IPY_MODEL_b4d3f09424ea4752b342b6c65db4ac61",
            "value": " 2.48M/? [00:00&lt;00:00, 31.5MB/s]"
          }
        },
        "8d6c5706876b45a0ba12d99199fb6c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c94d194b9db4d58b28af6aaf82e2ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a615484154c04082bff5f65005ba1816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acd854b100fe499a9567836ffb50e48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5812276ed8b24059a4ec769125dc86a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d6654f71c2a4b139d2e3f792e493677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4d3f09424ea4752b342b6c65db4ac61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e9b4d5ae3e64cfb8addd6846de58b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20e444327e4c4433893bbc2f9907bd5f",
              "IPY_MODEL_6b94d6178aee4b8180f1631bcbfb67de",
              "IPY_MODEL_d173aff5124446aa938589305b873beb"
            ],
            "layout": "IPY_MODEL_363f2e7dcb094e9fad2953453d21eb8b"
          }
        },
        "20e444327e4c4433893bbc2f9907bd5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e737736d6124813817cc4ec31a0582b",
            "placeholder": "​",
            "style": "IPY_MODEL_dedf0e363b074c018fb5d1714cc8d95b",
            "value": "merges.txt: "
          }
        },
        "6b94d6178aee4b8180f1631bcbfb67de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff6a5c107844abe81b097eb881dac5f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dac2dedd5b24fec80a2e812d1a671d8",
            "value": 1
          }
        },
        "d173aff5124446aa938589305b873beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce73859887294c0dbec2b374e3c0cd56",
            "placeholder": "​",
            "style": "IPY_MODEL_d2eaffb01d42440e92493b6c21242010",
            "value": " 494k/? [00:00&lt;00:00, 19.1MB/s]"
          }
        },
        "363f2e7dcb094e9fad2953453d21eb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e737736d6124813817cc4ec31a0582b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedf0e363b074c018fb5d1714cc8d95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cff6a5c107844abe81b097eb881dac5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1dac2dedd5b24fec80a2e812d1a671d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce73859887294c0dbec2b374e3c0cd56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2eaffb01d42440e92493b6c21242010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a8c118c77a2459fa13299124a45cfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ffbd78819904aa7ad21b5367e4cbf1c",
              "IPY_MODEL_faa04040779942779e0b1f61e3a54fda",
              "IPY_MODEL_5140801dd5a3418a839f5e95dd27caa4"
            ],
            "layout": "IPY_MODEL_caeec708f69b494d9ab63b084de0b5df"
          }
        },
        "8ffbd78819904aa7ad21b5367e4cbf1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b9cd74dcbd45abb0f30fde69735b09",
            "placeholder": "​",
            "style": "IPY_MODEL_7a992eb207eb4b13bd97255eb9e53249",
            "value": "normalizer.json: "
          }
        },
        "faa04040779942779e0b1f61e3a54fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60c6b71765c7408eb14b55043aa813f7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f4abb4131cf4f6abfe6ee2188378fa6",
            "value": 1
          }
        },
        "5140801dd5a3418a839f5e95dd27caa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_697caffaee16455baab533dfa3fcd493",
            "placeholder": "​",
            "style": "IPY_MODEL_125fdabfd76e496c9e94af92274ba117",
            "value": " 52.7k/? [00:00&lt;00:00, 2.49MB/s]"
          }
        },
        "caeec708f69b494d9ab63b084de0b5df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34b9cd74dcbd45abb0f30fde69735b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a992eb207eb4b13bd97255eb9e53249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60c6b71765c7408eb14b55043aa813f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2f4abb4131cf4f6abfe6ee2188378fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "697caffaee16455baab533dfa3fcd493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125fdabfd76e496c9e94af92274ba117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843d4f0941614df2b45388eef360fa3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_012497113be64e78b61da9ebd83aa0c9",
              "IPY_MODEL_2eef0002394a439ca27697012034796c",
              "IPY_MODEL_241ca908c96e4ecabfc62910eb17bbb6"
            ],
            "layout": "IPY_MODEL_881d6f1d8b3d4aee91b6e349103d83a9"
          }
        },
        "012497113be64e78b61da9ebd83aa0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1cbdf0530704d8ea3779ae0a4c7cf1c",
            "placeholder": "​",
            "style": "IPY_MODEL_8b3a0c7f48e04415a61756396a11ba92",
            "value": "added_tokens.json: "
          }
        },
        "2eef0002394a439ca27697012034796c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cadf18da327f4ec69a28a889094e034f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fca7c2360cdd4afe9e78f8e073919ee8",
            "value": 1
          }
        },
        "241ca908c96e4ecabfc62910eb17bbb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78142e8f68644c419534f08c658dcc6c",
            "placeholder": "​",
            "style": "IPY_MODEL_d8ef8bdb796c45e6a54b69ccbd3f2dd8",
            "value": " 34.6k/? [00:00&lt;00:00, 1.60MB/s]"
          }
        },
        "881d6f1d8b3d4aee91b6e349103d83a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1cbdf0530704d8ea3779ae0a4c7cf1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3a0c7f48e04415a61756396a11ba92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cadf18da327f4ec69a28a889094e034f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fca7c2360cdd4afe9e78f8e073919ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78142e8f68644c419534f08c658dcc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ef8bdb796c45e6a54b69ccbd3f2dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b007b2903934c02b2f1a3e593614b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9557e27644634dc383166b04c9211295",
              "IPY_MODEL_bb34fdd49e7a44a1b45bcf6e558c4838",
              "IPY_MODEL_2cf9048d77bd4d5d96775c87bca3f8f6"
            ],
            "layout": "IPY_MODEL_ba29857110fe47b8baaaaab7324163db"
          }
        },
        "9557e27644634dc383166b04c9211295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3017aec03d3418f8854dfbae940f193",
            "placeholder": "​",
            "style": "IPY_MODEL_3f4084bf8ab14fadabcf7c5035559536",
            "value": "special_tokens_map.json: "
          }
        },
        "bb34fdd49e7a44a1b45bcf6e558c4838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83bf4133bd6b4ca294caf8db0f995969",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c04f17e32b26486e8b88b48ed5d21e70",
            "value": 1
          }
        },
        "2cf9048d77bd4d5d96775c87bca3f8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17c6532089d49618e29c37d2a2336e3",
            "placeholder": "​",
            "style": "IPY_MODEL_247dcf678e694b8da6dc810c097f6b1b",
            "value": " 2.19k/? [00:00&lt;00:00, 103kB/s]"
          }
        },
        "ba29857110fe47b8baaaaab7324163db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3017aec03d3418f8854dfbae940f193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f4084bf8ab14fadabcf7c5035559536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83bf4133bd6b4ca294caf8db0f995969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c04f17e32b26486e8b88b48ed5d21e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a17c6532089d49618e29c37d2a2336e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "247dcf678e694b8da6dc810c097f6b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "711b9b1c4fe04bf48c552e51aa987bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0bf78ab1aff4b1cb04b6d9a8b25d3cf",
              "IPY_MODEL_90bd0bbdb3264a03a32c3f1773fbcec8",
              "IPY_MODEL_f49dd5e4bb2b4e9781057ec25ef7619f"
            ],
            "layout": "IPY_MODEL_0b01726282aa4dbd99ea2fc977e0c988"
          }
        },
        "b0bf78ab1aff4b1cb04b6d9a8b25d3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b154ca64a4d6454889a78051934676c8",
            "placeholder": "​",
            "style": "IPY_MODEL_d5b73c2af35049649a82f765f2f93a58",
            "value": "preprocessor_config.json: "
          }
        },
        "90bd0bbdb3264a03a32c3f1773fbcec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc310af465634127b01b737baaeafc9a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bef11a9cf854a3caeb03c503406d585",
            "value": 1
          }
        },
        "f49dd5e4bb2b4e9781057ec25ef7619f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e8a47d722b422e89258e0695c791f6",
            "placeholder": "​",
            "style": "IPY_MODEL_cb843a6024f946b0a33193ae167b738a",
            "value": " 185k/? [00:00&lt;00:00, 7.69MB/s]"
          }
        },
        "0b01726282aa4dbd99ea2fc977e0c988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b154ca64a4d6454889a78051934676c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b73c2af35049649a82f765f2f93a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc310af465634127b01b737baaeafc9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3bef11a9cf854a3caeb03c503406d585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43e8a47d722b422e89258e0695c791f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb843a6024f946b0a33193ae167b738a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}